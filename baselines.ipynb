{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandronicolini/IncrementalLearning/blob/main/baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOXnxAapLbVU"
      },
      "source": [
        "Import project files files from github \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbdul6vvZiSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7859bf-d4d1-44c1-805d-95436fe916f5"
      },
      "source": [
        "# upload work files from your git hub repository\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/alessandronicolini/IncrementalLearning.git # clone proj repository\n",
        "!rm -rf IncrementalLearning/README.md \n",
        "!rm -rf IncrementalLearning/baselines.ipynb\n",
        "\n",
        "path = 'IncrementalLearning/'\n",
        "if path not in sys.path:\n",
        "    sys.path.append('IncrementalLearning/')\n",
        "\n",
        "!pip3 install import_ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'IncrementalLearning' already exists and is not an empty directory.\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4jIc1PVTNP_"
      },
      "source": [
        "import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sufg5mojTQ3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f225c8-a8ba-44da-d299-1ed5bb3c2d7d"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import import_ipynb\n",
        "\n",
        "# project classes --------------------------------------------------------------\n",
        "from IncrementalLearning.cifar100 import ilCIFAR100\n",
        "from baselines.resnet import resnet32\n",
        "from info_recorder.info_log import InfoLog\n",
        "from models_benchmark.benchmark import Benchmark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /content/IncrementalLearning/cifar100.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MbZh4btZAL0"
      },
      "source": [
        "Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8WFt77-NOFj"
      },
      "source": [
        "# Define params\n",
        "\n",
        "NUM_RUN = 2\n",
        "SEEDS = [1,2,3]\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "CLASSES_PER_BATCH = 10\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "WEIGHT_DECAY = 1e-5\n",
        "LR = 2\n",
        "MOMENTUM = 0.9\n",
        "MILESTONES = [49, 63]\n",
        "GAMMA = 0.2\n",
        "\n",
        "SAVINGS_DIR = \"savings\"\n",
        "# Create savings folder\n",
        "try:\n",
        "    os.mkdir(SAVINGS_DIR)\n",
        "except FileExistsError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oxC1KcPZHTC"
      },
      "source": [
        "Define transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVaFpW0UFjgC"
      },
      "source": [
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformations for evaluation\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Blk7veRWwY"
      },
      "source": [
        "Prepare dataloders for each train, val test subset of the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyUjA03BRQsH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "a3d22a9b-b092-4822-df6d-e5faa78d31db"
      },
      "source": [
        "# dataloaders dict initialization\n",
        "dataloaders = {run:{batch:{'train':None, 'val':None, 'test':None} for batch in range(CLASSES_PER_BATCH)} for run in range(NUM_RUN)}\n",
        "\n",
        "# make dataloaders\n",
        "for run in range(NUM_RUN):\n",
        "    \n",
        "    # download dataset only on the first run\n",
        "    download = True\n",
        "    if run != 0:\n",
        "        download = False\n",
        "    \n",
        "    original_training_set = ilCIFAR100(CLASSES_PER_BATCH, seed=SEEDS[run])\n",
        "    original_test_set = ilCIFAR100(CLASSES_PER_BATCH, train=False, seed=SEEDS[run])\n",
        "    \n",
        "    train_indices, val_indices = original_training_set.get_train_val(0.1)\n",
        "    test_indices = original_training_set.getbatches()\n",
        "\n",
        "    for class_batch in range(CLASSES_PER_BATCH):\n",
        "        \n",
        "        # test indices are the uninion of test indices of batches seen up to now\n",
        "        test_indices = []\n",
        "        for i in range(class_batch+1):\n",
        "            test_indices += original_test_set.batches[i]\n",
        "\n",
        "        # make subsets\n",
        "        train_set = Subset(dataset=original_training_set, indices=train_indices[class_batch])\n",
        "        val_set = Subset(dataset=original_training_set, indices=val_indices[class_batch])\n",
        "        test_set = Subset(dataset=original_test_set, indices=test_indices[class_batch])\n",
        "\n",
        "        # make dataloaders\n",
        "        train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "        # add dataloaders to the dataloaders dict\n",
        "        dataloaders[run][class_batch]['train'] = train_dataloader\n",
        "        dataloaders[run][class_batch]['val'] = val_dataloader\n",
        "        dataloaders[run][class_batch]['test'] = test_dataloader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "[17, 72, 97, 8, 32, 15, 63, 57, 60, 83, 48, 26, 12, 62, 3, 49, 55, 77, 0, 92, 34, 29, 75, 13, 40, 85, 2, 74, 69, 1, 89, 27, 54, 98, 28, 56, 93, 35, 14, 22, 61, 43, 59, 71, 78, 18, 70, 88, 86, 41, 6, 11, 82, 46, 67, 7, 21, 95, 68, 42, 87, 19, 45, 31, 47, 25, 73, 30, 94, 23, 79, 39, 76, 58, 5, 64, 99, 91, 52, 24, 33, 80, 16, 66, 90, 96, 50, 84, 36, 44, 81, 10, 9, 38, 20, 4, 51, 65, 37, 53]\n",
            "Files already downloaded and verified\n",
            "[17, 72, 97, 8, 32, 15, 63, 57, 60, 83, 48, 26, 12, 62, 3, 49, 55, 77, 0, 92, 34, 29, 75, 13, 40, 85, 2, 74, 69, 1, 89, 27, 54, 98, 28, 56, 93, 35, 14, 22, 61, 43, 59, 71, 78, 18, 70, 88, 86, 41, 6, 11, 82, 46, 67, 7, 21, 95, 68, 42, 87, 19, 45, 31, 47, 25, 73, 30, 94, 23, 79, 39, 76, 58, 5, 64, 99, 91, 52, 24, 33, 80, 16, 66, 90, 96, 50, 84, 36, 44, 81, 10, 9, 38, 20, 4, 51, 65, 37, 53]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-972a9d46812f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moriginal_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0milCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASSES_PER_BATCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEEDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_training_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_training_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/IncrementalLearning/cifar100.ipynb\u001b[0m in \u001b[0;36mget_train_val\u001b[0;34m(self, valid)\u001b[0m\n",
            "\u001b[0;32m/content/IncrementalLearning/cifar100.ipynb\u001b[0m in \u001b[0;36mgetbatches\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFcJL2szqDAa"
      },
      "source": [
        "FINE TUNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsYAMeA9Cb1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ae097f-5100-4419-9be4-519965133c9b"
      },
      "source": [
        "for run in range(NUM_RUN):\n",
        "    benchmark = Benchmark(\n",
        "        num_epochs=NUM_EPOCHS, \n",
        "        dataloaders=dataloaders,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        saving_folder=\"savings/fine_tuning\")\n",
        "    \n",
        "    benchmark.set_criterion(nn.CrossEntropyLoss())\n",
        "    benchmark.set_infoLog(InfoLog, run)\n",
        "    benchmark.set_model(resnet32())\n",
        "\n",
        "    for class_batch in range(NUM_CLASS_BATCH):\n",
        "        parameters_to_optimize = benchmark.model.parameters()\n",
        "        benchmark.set_optimizer(optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY))\n",
        "        benchmark.set_scheduler(optim.lr_scheduler.MultiStepLR(benchmark.optimizer, milestones=MILESTONES, gamma=GAMMA))\n",
        "\n",
        "        benchmark.do_class_batch(run, class_batch)\n",
        "\n",
        "        benchmark.model.add_nodes(10) # forse Ã¨ meglio metterlo all'inizio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUN 0 ------------------------------------------------------------------------------------\n",
            "\n",
            "\tCLASS BATCH 0\n",
            "\n",
            "\tepoch  0:    train_acc: 0.096  train_loss: 2.991  val_acc: 0.100  val_loss: 2.513\n",
            "\tepoch  1:    train_acc: 0.106  train_loss: 2.386  val_acc: 0.100  val_loss: 2.401\n",
            "\tepoch  2:    train_acc: 0.103  train_loss: 2.385  val_acc: 0.098  val_loss: 2.365\n",
            "\tepoch  3:    train_acc: 0.092  train_loss: 2.387  val_acc: 0.100  val_loss: 2.367\n",
            "\tepoch  4:    train_acc: 0.099  train_loss: 2.389  val_acc: 0.100  val_loss: 2.379\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.365,  val_acc: 0.098,  epoch: 2\n",
            "\tTEST ACC: 0.101\n",
            "\n",
            "\n",
            "\tCLASS BATCH 1\n",
            "\n",
            "\tepoch  0:    train_acc: 0.096  train_loss: 2.509  val_acc: 0.100  val_loss: 2.409\n",
            "\tepoch  1:    train_acc: 0.102  train_loss: 2.396  val_acc: 0.100  val_loss: 2.404\n",
            "\tepoch  2:    train_acc: 0.100  train_loss: 2.386  val_acc: 0.100  val_loss: 2.404\n",
            "\tepoch  3:    train_acc: 0.099  train_loss: 2.387  val_acc: 0.100  val_loss: 2.379\n",
            "\tepoch  4:    train_acc: 0.099  train_loss: 2.361  val_acc: 0.100  val_loss: 2.335\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.335,  val_acc: 0.100,  epoch: 4\n",
            "\tTEST ACC: 0.052\n",
            "\n",
            "\n",
            "\tCLASS BATCH 2\n",
            "\n",
            "\tepoch  0:    train_acc: 0.083  train_loss: 3.178  val_acc: 0.100  val_loss: 2.332\n",
            "\tepoch  1:    train_acc: 0.096  train_loss: 2.364  val_acc: 0.100  val_loss: 2.479\n",
            "\tepoch  2:    train_acc: 0.096  train_loss: 2.387  val_acc: 0.098  val_loss: 2.327\n",
            "\tepoch  3:    train_acc: 0.096  train_loss: 2.390  val_acc: 0.100  val_loss: 2.455\n",
            "\tepoch  4:    train_acc: 0.103  train_loss: 2.389  val_acc: 0.100  val_loss: 2.377\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.327,  val_acc: 0.098,  epoch: 2\n",
            "\tTEST ACC: 0.034\n",
            "\n",
            "\n",
            "\tCLASS BATCH 3\n",
            "\n",
            "\tepoch  0:    train_acc: 0.084  train_loss: 3.843  val_acc: 0.100  val_loss: 2.557\n",
            "\tepoch  1:    train_acc: 0.104  train_loss: 2.406  val_acc: 0.100  val_loss: 2.372\n",
            "\tepoch  2:    train_acc: 0.095  train_loss: 2.375  val_acc: 0.100  val_loss: 2.393\n",
            "\tepoch  3:    train_acc: 0.106  train_loss: 2.387  val_acc: 0.100  val_loss: 2.421\n",
            "\tepoch  4:    train_acc: 0.100  train_loss: 2.372  val_acc: 0.100  val_loss: 2.389\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.372,  val_acc: 0.100,  epoch: 1\n",
            "\tTEST ACC: 0.026\n",
            "\n",
            "\n",
            "\tCLASS BATCH 4\n",
            "\n",
            "\tepoch  0:    train_acc: 0.077  train_loss: 4.491  val_acc: 0.100  val_loss: 2.477\n",
            "\tepoch  1:    train_acc: 0.105  train_loss: 2.359  val_acc: 0.100  val_loss: 2.329\n",
            "\tepoch  2:    train_acc: 0.095  train_loss: 2.382  val_acc: 0.100  val_loss: 2.347\n",
            "\tepoch  3:    train_acc: 0.099  train_loss: 2.372  val_acc: 0.100  val_loss: 2.420\n",
            "\tepoch  4:    train_acc: 0.106  train_loss: 2.375  val_acc: 0.100  val_loss: 2.354\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.329,  val_acc: 0.100,  epoch: 1\n",
            "\tTEST ACC: 0.021\n",
            "\n",
            "\n",
            "\tCLASS BATCH 5\n",
            "\n",
            "\tepoch  0:    train_acc: 0.086  train_loss: 4.965  val_acc: 0.100  val_loss: 2.402\n",
            "\tepoch  1:    train_acc: 0.091  train_loss: 2.381  val_acc: 0.100  val_loss: 2.382\n",
            "\tepoch  2:    train_acc: 0.095  train_loss: 2.377  val_acc: 0.100  val_loss: 2.445\n",
            "\tepoch  3:    train_acc: 0.101  train_loss: 2.389  val_acc: 0.100  val_loss: 2.359\n",
            "\tepoch  4:    train_acc: 0.100  train_loss: 2.370  val_acc: 0.100  val_loss: 2.424\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.359,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.017\n",
            "\n",
            "\n",
            "\tCLASS BATCH 6\n",
            "\n",
            "\tepoch  0:    train_acc: 0.088  train_loss: 5.123  val_acc: 0.100  val_loss: 2.337\n",
            "\tepoch  1:    train_acc: 0.094  train_loss: 2.372  val_acc: 0.100  val_loss: 2.421\n",
            "\tepoch  2:    train_acc: 0.101  train_loss: 2.393  val_acc: 0.100  val_loss: 2.387\n",
            "\tepoch  3:    train_acc: 0.096  train_loss: 2.358  val_acc: 0.100  val_loss: 2.395\n",
            "\tepoch  4:    train_acc: 0.096  train_loss: 2.395  val_acc: 0.100  val_loss: 2.429\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.337,  val_acc: 0.100,  epoch: 0\n",
            "\tTEST ACC: 0.014\n",
            "\n",
            "\n",
            "\tCLASS BATCH 7\n",
            "\n",
            "\tepoch  0:    train_acc: 0.082  train_loss: 5.490  val_acc: 0.100  val_loss: 2.417\n",
            "\tepoch  1:    train_acc: 0.103  train_loss: 2.364  val_acc: 0.100  val_loss: 2.419\n",
            "\tepoch  2:    train_acc: 0.100  train_loss: 2.372  val_acc: 0.100  val_loss: 2.415\n",
            "\tepoch  3:    train_acc: 0.098  train_loss: 2.366  val_acc: 0.100  val_loss: 2.359\n",
            "\tepoch  4:    train_acc: 0.099  train_loss: 2.372  val_acc: 0.100  val_loss: 2.384\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.359,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.013\n",
            "\n",
            "\n",
            "\tCLASS BATCH 8\n",
            "\n",
            "\tepoch  0:    train_acc: 0.078  train_loss: 5.412  val_acc: 0.100  val_loss: 2.440\n",
            "\tepoch  1:    train_acc: 0.099  train_loss: 2.375  val_acc: 0.100  val_loss: 2.394\n",
            "\tepoch  2:    train_acc: 0.095  train_loss: 2.371  val_acc: 0.100  val_loss: 2.391\n",
            "\tepoch  3:    train_acc: 0.098  train_loss: 2.400  val_acc: 0.100  val_loss: 2.344\n",
            "\tepoch  4:    train_acc: 0.093  train_loss: 2.372  val_acc: 0.100  val_loss: 2.359\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.344,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.011\n",
            "\n",
            "\n",
            "\tCLASS BATCH 9\n",
            "\n",
            "\tepoch  0:    train_acc: 0.079  train_loss: 5.566  val_acc: 0.100  val_loss: 2.393\n",
            "\tepoch  1:    train_acc: 0.098  train_loss: 2.375  val_acc: 0.100  val_loss: 2.326\n",
            "\tepoch  2:    train_acc: 0.095  train_loss: 2.357  val_acc: 0.100  val_loss: 2.323\n",
            "\tepoch  3:    train_acc: 0.101  train_loss: 2.375  val_acc: 0.100  val_loss: 2.482\n",
            "\tepoch  4:    train_acc: 0.092  train_loss: 2.384  val_acc: 0.100  val_loss: 2.346\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.323,  val_acc: 0.100,  epoch: 2\n",
            "\tTEST ACC: 0.010\n",
            "\n",
            "\n",
            "RUN 1 ------------------------------------------------------------------------------------\n",
            "\n",
            "\tCLASS BATCH 0\n",
            "\n",
            "\tepoch  0:    train_acc: 0.097  train_loss: 3.046  val_acc: 0.100  val_loss: 2.418\n",
            "\tepoch  1:    train_acc: 0.099  train_loss: 2.392  val_acc: 0.100  val_loss: 2.628\n",
            "\tepoch  2:    train_acc: 0.100  train_loss: 2.369  val_acc: 0.100  val_loss: 2.336\n",
            "\tepoch  3:    train_acc: 0.098  train_loss: 2.367  val_acc: 0.100  val_loss: 2.381\n",
            "\tepoch  4:    train_acc: 0.104  train_loss: 2.378  val_acc: 0.100  val_loss: 2.339\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.336,  val_acc: 0.100,  epoch: 2\n",
            "\tTEST ACC: 0.100\n",
            "\n",
            "\n",
            "\tCLASS BATCH 1\n",
            "\n",
            "\tepoch  0:    train_acc: 0.106  train_loss: 2.505  val_acc: 0.100  val_loss: 2.350\n",
            "\tepoch  1:    train_acc: 0.105  train_loss: 2.397  val_acc: 0.100  val_loss: 2.346\n",
            "\tepoch  2:    train_acc: 0.102  train_loss: 2.369  val_acc: 0.100  val_loss: 2.342\n",
            "\tepoch  3:    train_acc: 0.093  train_loss: 2.367  val_acc: 0.100  val_loss: 2.363\n",
            "\tepoch  4:    train_acc: 0.098  train_loss: 2.378  val_acc: 0.100  val_loss: 2.386\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.342,  val_acc: 0.100,  epoch: 2\n",
            "\tTEST ACC: 0.050\n",
            "\n",
            "\n",
            "\tCLASS BATCH 2\n",
            "\n",
            "\tepoch  0:    train_acc: 0.080  train_loss: 3.229  val_acc: 0.100  val_loss: 2.391\n",
            "\tepoch  1:    train_acc: 0.106  train_loss: 2.388  val_acc: 0.100  val_loss: 2.394\n",
            "\tepoch  2:    train_acc: 0.090  train_loss: 2.364  val_acc: 0.100  val_loss: 2.335\n",
            "\tepoch  3:    train_acc: 0.096  train_loss: 2.385  val_acc: 0.100  val_loss: 2.343\n",
            "\tepoch  4:    train_acc: 0.092  train_loss: 2.374  val_acc: 0.100  val_loss: 2.375\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.335,  val_acc: 0.100,  epoch: 2\n",
            "\tTEST ACC: 0.033\n",
            "\n",
            "\n",
            "\tCLASS BATCH 3\n",
            "\n",
            "\tepoch  0:    train_acc: 0.091  train_loss: 3.822  val_acc: 0.100  val_loss: 2.358\n",
            "\tepoch  1:    train_acc: 0.096  train_loss: 2.366  val_acc: 0.100  val_loss: 2.366\n",
            "\tepoch  2:    train_acc: 0.100  train_loss: 2.373  val_acc: 0.100  val_loss: 2.368\n",
            "\tepoch  3:    train_acc: 0.099  train_loss: 2.371  val_acc: 0.100  val_loss: 2.399\n",
            "\tepoch  4:    train_acc: 0.099  train_loss: 2.379  val_acc: 0.100  val_loss: 2.381\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.358,  val_acc: 0.100,  epoch: 0\n",
            "\tTEST ACC: 0.025\n",
            "\n",
            "\n",
            "\tCLASS BATCH 4\n",
            "\n",
            "\tepoch  0:    train_acc: 0.078  train_loss: 4.537  val_acc: 0.100  val_loss: 2.372\n",
            "\tepoch  1:    train_acc: 0.098  train_loss: 2.420  val_acc: 0.100  val_loss: 2.435\n",
            "\tepoch  2:    train_acc: 0.097  train_loss: 2.368  val_acc: 0.100  val_loss: 2.351\n",
            "\tepoch  3:    train_acc: 0.099  train_loss: 2.373  val_acc: 0.100  val_loss: 2.350\n",
            "\tepoch  4:    train_acc: 0.094  train_loss: 2.402  val_acc: 0.100  val_loss: 2.401\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.350,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.020\n",
            "\n",
            "\n",
            "\tCLASS BATCH 5\n",
            "\n",
            "\tepoch  0:    train_acc: 0.079  train_loss: 4.920  val_acc: 0.100  val_loss: 2.437\n",
            "\tepoch  1:    train_acc: 0.102  train_loss: 2.387  val_acc: 0.100  val_loss: 2.382\n",
            "\tepoch  2:    train_acc: 0.107  train_loss: 2.360  val_acc: 0.100  val_loss: 2.571\n",
            "\tepoch  3:    train_acc: 0.104  train_loss: 2.378  val_acc: 0.100  val_loss: 2.376\n",
            "\tepoch  4:    train_acc: 0.097  train_loss: 2.370  val_acc: 0.100  val_loss: 2.324\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.324,  val_acc: 0.100,  epoch: 4\n",
            "\tTEST ACC: 0.017\n",
            "\n",
            "\n",
            "\tCLASS BATCH 6\n",
            "\n",
            "\tepoch  0:    train_acc: 0.089  train_loss: 5.027  val_acc: 0.100  val_loss: 2.361\n",
            "\tepoch  1:    train_acc: 0.093  train_loss: 2.363  val_acc: 0.100  val_loss: 2.427\n",
            "\tepoch  2:    train_acc: 0.104  train_loss: 2.393  val_acc: 0.100  val_loss: 2.454\n",
            "\tepoch  3:    train_acc: 0.093  train_loss: 2.416  val_acc: 0.100  val_loss: 2.366\n",
            "\tepoch  4:    train_acc: 0.101  train_loss: 2.399  val_acc: 0.100  val_loss: 2.328\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.328,  val_acc: 0.100,  epoch: 4\n",
            "\tTEST ACC: 0.014\n",
            "\n",
            "\n",
            "\tCLASS BATCH 7\n",
            "\n",
            "\tepoch  0:    train_acc: 0.085  train_loss: 5.074  val_acc: 0.100  val_loss: 2.363\n",
            "\tepoch  1:    train_acc: 0.104  train_loss: 2.391  val_acc: 0.100  val_loss: 2.352\n",
            "\tepoch  2:    train_acc: 0.096  train_loss: 2.380  val_acc: 0.100  val_loss: 2.380\n",
            "\tepoch  3:    train_acc: 0.099  train_loss: 2.371  val_acc: 0.100  val_loss: 2.335\n",
            "\tepoch  4:    train_acc: 0.104  train_loss: 2.377  val_acc: 0.100  val_loss: 2.363\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.335,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.013\n",
            "\n",
            "\n",
            "\tCLASS BATCH 8\n",
            "\n",
            "\tepoch  0:    train_acc: 0.088  train_loss: 5.338  val_acc: 0.100  val_loss: 2.389\n",
            "\tepoch  1:    train_acc: 0.101  train_loss: 2.409  val_acc: 0.100  val_loss: 2.413\n",
            "\tepoch  2:    train_acc: 0.097  train_loss: 2.378  val_acc: 0.100  val_loss: 2.406\n",
            "\tepoch  3:    train_acc: 0.107  train_loss: 2.400  val_acc: 0.100  val_loss: 2.348\n",
            "\tepoch  4:    train_acc: 0.097  train_loss: 2.369  val_acc: 0.100  val_loss: 2.379\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.348,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.011\n",
            "\n",
            "\n",
            "\tCLASS BATCH 9\n",
            "\n",
            "\tepoch  0:    train_acc: 0.080  train_loss: 5.308  val_acc: 0.100  val_loss: 2.398\n",
            "\tepoch  1:    train_acc: 0.101  train_loss: 2.357  val_acc: 0.100  val_loss: 2.397\n",
            "\tepoch  2:    train_acc: 0.101  train_loss: 2.386  val_acc: 0.100  val_loss: 2.386\n",
            "\tepoch  3:    train_acc: 0.096  train_loss: 2.378  val_acc: 0.100  val_loss: 2.367\n",
            "\tepoch  4:    train_acc: 0.106  train_loss: 2.393  val_acc: 0.100  val_loss: 2.383\n",
            "\n",
            "\tBEST RESULTS:\tval_loss: 2.367,  val_acc: 0.100,  epoch: 3\n",
            "\tTEST ACC: 0.010\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}