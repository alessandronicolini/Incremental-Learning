{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iCarl_nme_bce_ce.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1029c1d98061427f9663b8ee9c292ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0506263267be44709e5f14fbcf87088e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c42a6e4ddb74e8d9b16540709e25a58",
              "IPY_MODEL_404591efac9a472caaf2ad1ac368011b"
            ]
          }
        },
        "0506263267be44709e5f14fbcf87088e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c42a6e4ddb74e8d9b16540709e25a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b2fb9d07bff494e8460d7539c5ee73b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 70,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 70,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66fb8b96c9e74d7a99e13224d633d95f"
          }
        },
        "404591efac9a472caaf2ad1ac368011b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1460ac4094164cd58a6a649bdc333871",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 70/70 [05:29&lt;00:00,  4.71s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56803b2f6a4647fcbdf026ab47a7dc3b"
          }
        },
        "6b2fb9d07bff494e8460d7539c5ee73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66fb8b96c9e74d7a99e13224d633d95f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1460ac4094164cd58a6a649bdc333871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56803b2f6a4647fcbdf026ab47a7dc3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "028fa97db4ad43c2b54bccc6593d9daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed13744c8e5c4e5da751b49fce4f89ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cee03650e17544c7b094029164664a32",
              "IPY_MODEL_067b8cd528ff4071be48a1834a8e96ea"
            ]
          }
        },
        "ed13744c8e5c4e5da751b49fce4f89ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cee03650e17544c7b094029164664a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_044992e9392049928b06876f731f167e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 70,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 70,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dec76f7dceb242bf8a2cdb2a182e1955"
          }
        },
        "067b8cd528ff4071be48a1834a8e96ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7221a9c79720481ab7c499e1c3233536",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 70/70 [09:17&lt;00:00,  7.97s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bebc1fdda55846199430acf85e95bc9a"
          }
        },
        "044992e9392049928b06876f731f167e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dec76f7dceb242bf8a2cdb2a182e1955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7221a9c79720481ab7c499e1c3233536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bebc1fdda55846199430acf85e95bc9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandronicolini/IncrementalLearning/blob/main/iCarl_nme_bce_mse_con_errore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH7YHXeh0hFj",
        "outputId": "2414566b-1dc7-4b42-854d-b92b4d234338"
      },
      "source": [
        "!pip3 install 'import_ipynb'\n",
        "!pip3 install 'tqdm'\n",
        "\n",
        "!rm -r IncrementalLearning\n",
        "# upload work files from your git hub repository\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/alessandronicolini/IncrementalLearning.git # clone proj repository\n",
        "!rm -rf IncrementalLearning/README.md \n",
        "!rm -rf IncrementalLearning/baselines.ipynb\n",
        "\n",
        "path = 'IncrementalLearning/'\n",
        "if path not in sys.path:\n",
        "    sys.path.append('IncrementalLearning/')\n",
        "\n",
        "!pip3 install import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=7d71a937ab7b7db50e9857befcf33eb5c5b8d08eeaaa3afab936ffdb8e54e994\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "rm: cannot remove 'IncrementalLearning': No such file or directory\n",
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 482 (delta 1), reused 0 (delta 0), pack-reused 474\u001b[K\n",
            "Receiving objects: 100% (482/482), 442.40 KiB | 16.38 MiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4jUchQ1EAI"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "import copy\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix as s_cm\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "import import_ipynb\n",
        "from IncrementalLearning.cifar100 import ilCIFAR100\n",
        "\n",
        "from IncrementalLearning.resnet_cifar import resnet32\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzqwQeHB1Tg-"
      },
      "source": [
        "class icarl(nn.Module):\n",
        "  def __init__(self,n_classes=100, classificationLoss = nn.BCEWithLogitsLoss(), distillationLoss = nn.CrossEntropyLoss()):\n",
        "    super(icarl, self).__init__()\n",
        "\n",
        "    self.classification_loss = classificationLoss\n",
        "    self.distillation_loss = distillationLoss\n",
        "\n",
        "    self.model = resnet32(num_classes=n_classes)\n",
        "    self.feature_extractor = self.model.features\n",
        "    self.lr = 2\n",
        "    self.gamma = 0.2\n",
        "    self.weight_decay =1e-5 \n",
        "    self.milestones = [49,63]\n",
        "    self.batch_size = 128\n",
        "    self.numepochs = 70\n",
        "    self.n_classes = 0\n",
        "    self.n_known = 0\n",
        "    self.feature_size=64\n",
        "    self.momentum=0.9\n",
        "    self.criterion=nn.BCEWithLogitsLoss()\n",
        "    self.compute_means = True\n",
        "    self.exemplar_means = None\n",
        "    self.exemplar_sets = []\n",
        "    self.exemplar_labels = []\n",
        "    self.NUM_BATCHES=10\n",
        "    self.randomseed=7\n",
        "    self.trainloader=None\n",
        "    self.testloader=None\n",
        "    self.CLASSES_PER_BATCH=10\n",
        "    self.original_training_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed)\n",
        "    self.original_test_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed, train=False)\n",
        "\n",
        "    self.classes_seen=0\n",
        "    self.diz = self.original_training_set.get_dict()\n",
        "\n",
        "  def update_parameters(self):\n",
        "    old_model = copy.deepcopy(self)\n",
        "    old_model.eval()\n",
        "    old_model.to('cuda')\n",
        "    n_classes = self.classes_seen+self.CLASSES_PER_BATCH\n",
        "    print(n_classes)\n",
        "    optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.milestones, gamma=self.gamma)\n",
        "    for epoch in tqdm(range(self.numepochs)):\n",
        "        \n",
        "      for _, inputs, labels in self.trainloader:\n",
        "        inputs = Variable(torch.FloatTensor(inputs)).cuda()\n",
        "        labels = torch.tensor([torch.tensor(self.diz[c.item()]) for c in labels])\n",
        "\n",
        "        labels=Variable(labels).to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        outputs=self.forward(inputs)\n",
        "\n",
        "        labels_encoded = F.one_hot(labels,100).float().cuda() #CAMBIARE ONE_HOT\n",
        "        \n",
        "        if self.classes_seen:\n",
        "          old_target = old_model.forward(inputs).cuda()\n",
        "          old_target = torch.sigmoid(old_target).cuda()\n",
        "          \n",
        "          loss = self.classification_loss(outputs[:,self.classes_seen:self.classes_seen+self.CLASSES_PER_BATCH], labels_encoded[:,self.classes_seen:self.classes_seen+self.CLASSES_PER_BATCH])\n",
        "          dist_loss = self.distillation_loss(outputs[:,:self.classes_seen], old_target[:,:self.classes_seen])\n",
        "          loss += dist_loss\n",
        "        else:\n",
        "          loss = self.classification_loss(outputs[:,:self.CLASSES_PER_BATCH],labels_encoded[:,:self.CLASSES_PER_BATCH]) \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "      scheduler.step()\n",
        "    print(loss)\n",
        "\n",
        "  def classify_nme(self, input_batch):\n",
        "    min_distances = float('inf')*torch.ones(len(input_batch)).cuda() # shape: batch_size --> 128\n",
        "    y_pred = torch.zeros(len(input_batch), dtype=torch.int8).cuda() # shape: batch_size --> 128\n",
        "    input_features = self.feature_extractor(input_batch) # shape: (batch_size, feature_size) --> (128, 64)\n",
        "\n",
        "    for i in range(len(self.exemplar_sets)):\n",
        "      ex_mean = self.exemplar_means[i,:]\n",
        "\n",
        "      # compute distances between inputs features and exemplar set means\n",
        "      pdist = nn.PairwiseDistance(p=2)\n",
        "      distances = pdist(input_features, ex_mean) # shape: batch_size --> 128\n",
        "\n",
        "      # update min distancies and predicted labels\n",
        "      mask = distances < min_distances\n",
        "      min_distances[mask] = distances[mask]\n",
        "      y_pred[mask] = self.exemplar_labels[i]\n",
        "\n",
        "    return y_pred\n",
        "    \n",
        "\n",
        "  def get_new_exemplars(self, batch, m):\n",
        "    loader = torch.utils.data.DataLoader(batch, batch_size=self.batch_size,shuffle=False, num_workers=4)\n",
        "    features = np.zeros((0,self.feature_size))\n",
        "    indices = np.zeros((0), dtype=int)\n",
        "    with torch.no_grad():\n",
        "      for indexes, images, labels in loader:\n",
        "        images = images.cuda()\n",
        "        feature = self.feature_extractor(images).data.cpu().numpy()\n",
        "        feature = normalize(feature, axis=1, norm='l2')\n",
        "        features = np.concatenate((features,feature), axis=0)\n",
        "        indices = np.concatenate((indices,indexes), axis=0)\n",
        "\n",
        "    class_mean = np.mean(features, axis=0)\n",
        "    class_mean = class_mean / np.linalg.norm(class_mean)  # Normalize\n",
        "\n",
        "    exemplar_set = []\n",
        "    exemplar_features = np.zeros((0,self.feature_size))\n",
        "\n",
        "    for k in range(1, int(m)+1):\n",
        "        S = np.sum(exemplar_features, axis=0)\n",
        "        phi = features\n",
        "        mu = class_mean\n",
        "        mu_p = 1.0 / k * (phi + S)\n",
        "        mu_p = normalize(mu_p, axis=1, norm='l2')\n",
        "        i = np.argmin(np.sqrt(np.sum((mu - mu_p) ** 2, axis=1)))\n",
        "        exemplar_set.append(indices[i])\n",
        "        addfeature =  np.expand_dims(features[i], axis=0)\n",
        "        exemplar_features = np.concatenate((exemplar_features,addfeature), axis=0)\n",
        "\n",
        "        #remove duplicates\n",
        "        features = np.delete(features, i, 0)\n",
        "        indices = np.delete(indices, i, 0)\n",
        "        \n",
        "    self.exemplar_sets.append(exemplar_set)\n",
        "        \n",
        "  def reduce_old_exemplars(self,m):\n",
        "    for y, P_y in enumerate(self.exemplar_sets):\n",
        "            self.exemplar_sets[y] = P_y[:int(m)]\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.model = self.model.cuda()\n",
        "    return self.model.forward(x)\n",
        "\n",
        "  def __accuracy_fc(self, dl, model, mapper):\n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    for  _, images, labels in dl:\n",
        "      labels = torch.tensor([torch.tensor(mapper[c.item()]) for c in labels])\n",
        "      labels = labels.cuda()\n",
        "      images = images.cuda()\n",
        "      outputs = self.forward(images)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      total += len(labels)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return acc\n",
        "\n",
        "  def __accuracy_nme(self, dl, model):\n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    for  _, images, labels in dl:\n",
        "      labels = labels.cuda()\n",
        "      images = images.cuda()\n",
        "      outputs = model(images)\n",
        "      preds = self.classify_nme(images)\n",
        "      total += len(labels)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "    acc = 100 * correct / total\n",
        "    return acc\n",
        "\n",
        "  def training_model(self):\n",
        "    \n",
        "    train_indices = self.original_training_set.get_batch_indexes()\n",
        "    test_indices = self.original_test_set.get_batch_indexes()\n",
        "    batches=self.original_training_set.getbatches()\n",
        "    current_test_indexes=[]\n",
        "    acc=[]\n",
        "    accuracy=0\n",
        "    for i in range(self.NUM_BATCHES):\n",
        "      \n",
        "      for exemplars in self.exemplar_sets:\n",
        "        train_indices[i]=np.concatenate([train_indices[i], np.array(exemplars)])\n",
        "        #print(exemplars)\n",
        "\n",
        "      train_dataset = Subset(self.original_training_set, train_indices[i])\n",
        "      current_test_indexes += test_indices[i].tolist()\n",
        "      test_dataset = Subset(self.original_test_set,current_test_indexes)\n",
        "\n",
        "      actual_test_dataset=Subset(self.original_test_set,test_indices[i])\n",
        "\n",
        "      self.trainloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "      self.testloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4, drop_last=True)      \n",
        "      self.actualtestloader = DataLoader(actual_test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4, drop_last=True)    \n",
        "      self.train()\n",
        "      self.update_parameters()    \n",
        "      self.classes_seen += 10\n",
        "      self.eval() # Set Network to evaluation mode\n",
        "\n",
        "      # reduce exemplars\n",
        "      m=int(2000/(int(i*10+10)))\n",
        "      self.reduce_old_exemplars(m) \n",
        "      # add new exemplar sets\n",
        "      for classlabel in batches[i]:\n",
        "        indexes_class = self.original_training_set.get_class_indexes(classlabel)\n",
        "        current_class = Subset(self.original_training_set, indexes_class)\n",
        "        self.get_new_exemplars(current_class, m)\n",
        "      \n",
        "      # compute means of exemplar set\n",
        "      # cycle for each exemplar set\n",
        "      self.exemplar_means = torch.zeros((0, self.feature_size), dtype=torch.float).cuda()\n",
        "      self.exemplar_labels = []\n",
        "      for i in range(len(self.exemplar_sets)):\n",
        "        exemplars_dataset = Subset(self.original_training_set, self.exemplar_sets[i])\n",
        "        exemplars_loader = torch.utils.data.DataLoader(exemplars_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
        "        ex_features = torch.zeros((0, self.feature_size), dtype=torch.float).cuda() # alla fine shape: (len(exemplar_set), feature_size) --> (m, 64)\n",
        "      \n",
        "        with torch.no_grad():\n",
        "          _, _, exemplar_label = self.original_training_set.__getitem__(self.exemplar_sets[i][0]) \n",
        "          self.exemplar_labels.append(exemplar_label)\n",
        "          # cycle for each batch in the current exemplar set\n",
        "          for _,  exemplars, _ in exemplars_loader:\n",
        "          \n",
        "            # get exemplars features\n",
        "            exemplars = exemplars.cuda()\n",
        "            features = self.feature_extractor(exemplars) # shape: (len(exemplars), feature_size)\n",
        "          \n",
        "            # normalize \n",
        "            feature_norms = torch.norm(features, p=2, dim=1) # shape: len(exemplars)\n",
        "            feature_norms.unsqueeze_(1) # shape: (len(exemplars), 1)\n",
        "            features = features/feature_norms\n",
        "          \n",
        "            # concatenate over columns\n",
        "            ex_features = torch.cat((ex_features, features), dim=0)\n",
        "          \n",
        "        # compute current exemplar set mean and normalize it\n",
        "        ex_mean = torch.mean(ex_features, dim=0) # shape: feature_size --> 64\n",
        "        ex_mean = ex_mean/torch.norm(ex_mean)\n",
        "        ex_mean.unsqueeze_(0) # shape: (1, feature_size) --> (1, 64)\n",
        "        self.exemplar_means = torch.cat((self.exemplar_means, ex_mean), dim=0) # shape: (n_examplar set, feature size)\n",
        "      \n",
        "\n",
        "      print('accuracy on training set:', self.__accuracy_fc(self.trainloader,self,self.diz))\n",
        "      # print('accuracy on test set:', self.__accuracy_on(self.testloader,self,self.diz))\n",
        "      print('accuracy on whole test set:', self.__accuracy_nme(self.testloader, self))\n",
        "      print('accuracy on actual test set:', self.__accuracy_nme(self.actualtestloader, self))\n",
        "      print('-' * 80)\n",
        "      acc.append(accuracy)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZYiiNSL7eG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1029c1d98061427f9663b8ee9c292ef2",
            "0506263267be44709e5f14fbcf87088e",
            "5c42a6e4ddb74e8d9b16540709e25a58",
            "404591efac9a472caaf2ad1ac368011b",
            "6b2fb9d07bff494e8460d7539c5ee73b",
            "66fb8b96c9e74d7a99e13224d633d95f",
            "1460ac4094164cd58a6a649bdc333871",
            "56803b2f6a4647fcbdf026ab47a7dc3b",
            "028fa97db4ad43c2b54bccc6593d9daa",
            "ed13744c8e5c4e5da751b49fce4f89ae",
            "cee03650e17544c7b094029164664a32",
            "067b8cd528ff4071be48a1834a8e96ea",
            "044992e9392049928b06876f731f167e",
            "dec76f7dceb242bf8a2cdb2a182e1955",
            "7221a9c79720481ab7c499e1c3233536",
            "bebc1fdda55846199430acf85e95bc9a"
          ]
        },
        "outputId": "df2b3a37-d1c5-47a8-8133-4e1f49464e18"
      },
      "source": [
        "model = icarl(classificationLoss = nn.BCEWithLogitsLoss(), distillationLoss = nn.MSELoss()).cuda()\n",
        "model.training_model()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1029c1d98061427f9663b8ee9c292ef2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy on training set: 91.56650641025641\n",
            "accuracy on whole test set: 83.14732142857143\n",
            "accuracy on actual test set: 83.14732142857143\n",
            "--------------------------------------------------------------------------------\n",
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "028fa97db4ad43c2b54bccc6593d9daa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-f250b2a9e193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micarl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistillationLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-642165733549>\u001b[0m in \u001b[0;36mtraining_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mindexes_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_training_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_class_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mcurrent_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_training_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_new_exemplars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0;31m# compute means of exemplar set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-642165733549>\u001b[0m in \u001b[0;36mget_new_exemplars\u001b[0;34m(self, batch, m)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     X = check_array(X, sparse_format, copy=copy,\n\u001b[0;32m-> 1705\u001b[0;31m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m   1706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIXIk8WJXU0N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}