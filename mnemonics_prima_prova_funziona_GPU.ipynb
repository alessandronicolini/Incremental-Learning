{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnemonics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccbc0f47988b422eb18a30ca8f8c12d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9659f01932e41c782b49d5e1a58dddc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03ad32cbfc33431292b47ad76402d85c",
              "IPY_MODEL_9eeebe382cce48f28cc2fb0440b48606"
            ]
          }
        },
        "e9659f01932e41c782b49d5e1a58dddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ad32cbfc33431292b47ad76402d85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dfbf80ce40c8471ab3232eb6c812647b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f6278cfeaae452da9fae635799d9052"
          }
        },
        "9eeebe382cce48f28cc2fb0440b48606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_745cee4f1bf74950a8de938ac34f68e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 104048066.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff03856c16e043a092572de3c4765725"
          }
        },
        "dfbf80ce40c8471ab3232eb6c812647b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f6278cfeaae452da9fae635799d9052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "745cee4f1bf74950a8de938ac34f68e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff03856c16e043a092572de3c4765725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d53e3506b58945b7ba8db19ff786f80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f2e6fdfd5a0433784656235d58f597d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_99fd10043006459e9cfec3bb2141873c",
              "IPY_MODEL_b04dfe0b5ec64c0b8faf76859a62a3ef"
            ]
          }
        },
        "2f2e6fdfd5a0433784656235d58f597d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99fd10043006459e9cfec3bb2141873c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83b87e5600f949199c5f98dce065e05d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a786858e657843dc8d127da53eb0d232"
          }
        },
        "b04dfe0b5ec64c0b8faf76859a62a3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d54d6f7ee6cb418c81732e7a3e44b78c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:48&lt;00:00, 48.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb498186ab644d6f88ac46ab4a758714"
          }
        },
        "83b87e5600f949199c5f98dce065e05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a786858e657843dc8d127da53eb0d232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d54d6f7ee6cb418c81732e7a3e44b78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb498186ab644d6f88ac46ab4a758714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f0ada759799428a9d10d14bdb0ec2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83697436221d486fa5d8ed3fb2f0f82d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9009c3033812419caae2a4f18b54b0f6",
              "IPY_MODEL_2887d076242147cd9e921f2eb5a15268"
            ]
          }
        },
        "83697436221d486fa5d8ed3fb2f0f82d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9009c3033812419caae2a4f18b54b0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13a21820024a47d6ba6137ba50d54644",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d43852428e24dd6aaa5073206b4f821"
          }
        },
        "2887d076242147cd9e921f2eb5a15268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4024bff1ed2749eea2c7374f25374a2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:06&lt;00:00,  6.97s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31ca7648ceda481db20ffa470e5ae3d9"
          }
        },
        "13a21820024a47d6ba6137ba50d54644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d43852428e24dd6aaa5073206b4f821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4024bff1ed2749eea2c7374f25374a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31ca7648ceda481db20ffa470e5ae3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandronicolini/IncrementalLearning/blob/main/mnemonics_prima_prova_funziona_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH7YHXeh0hFj",
        "outputId": "753216df-550a-4d83-add9-0eecbec1ac27"
      },
      "source": [
        "!pip3 install 'import_ipynb'\n",
        "!pip3 install 'tqdm'\n",
        "\n",
        "!rm -r IncrementalLearning\n",
        "# upload work files from your git hub repository\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/alessandronicolini/IncrementalLearning.git # clone proj repository\n",
        "!rm -rf IncrementalLearning/README.md \n",
        "!rm -rf IncrementalLearning/baselines.ipynb\n",
        "\n",
        "path = 'IncrementalLearning/'\n",
        "if path not in sys.path:\n",
        "    sys.path.append('IncrementalLearning/')\n",
        "\n",
        "!pip3 install import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=d8fb7487a8351c03f8142d50d44231aae364f44d3ad812d88bafcecd614d55b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "rm: cannot remove 'IncrementalLearning': No such file or directory\n",
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 529 (delta 32), reused 0 (delta 0), pack-reused 474\u001b[K\n",
            "Receiving objects: 100% (529/529), 513.85 KiB | 21.41 MiB/s, done.\n",
            "Resolving deltas: 100% (307/307), done.\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4jUchQ1EAI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "ccbc0f47988b422eb18a30ca8f8c12d2",
            "e9659f01932e41c782b49d5e1a58dddc",
            "03ad32cbfc33431292b47ad76402d85c",
            "9eeebe382cce48f28cc2fb0440b48606",
            "dfbf80ce40c8471ab3232eb6c812647b",
            "6f6278cfeaae452da9fae635799d9052",
            "745cee4f1bf74950a8de938ac34f68e9",
            "ff03856c16e043a092572de3c4765725"
          ]
        },
        "outputId": "a18a4360-8dfe-4941-9ff9-544bccc305c5"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "import copy\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from torch.utils.data import Subset, DataLoader, Dataset\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "import import_ipynb\n",
        "from IncrementalLearning.cifar100 import ilCIFAR100\n",
        "from google.colab import output\n",
        "\n",
        "from IncrementalLearning.resnet_cifar import resnet32\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /content/IncrementalLearning/cifar100.ipynb\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccbc0f47988b422eb18a30ca8f8c12d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "importing Jupyter notebook from /content/IncrementalLearning/resnet_cifar.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzqwQeHB1Tg-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "9295ba2f-26fe-46ef-8e75-42cd2443743d"
      },
      "source": [
        "\n",
        "def process_inputs_fp(tg_model, inputs, fusion_mode=False, feature_mode=False):\n",
        "  tg_model_group1 = [tg_model.conv1, tg_model.bn1, tg_model.relu, tg_model.layer1]\n",
        "  tg_model_group1 = nn.Sequential(*tg_model_group1)\n",
        "  tg_fp1 = tg_model_group1(inputs)\n",
        "  fp1 = tg_fp1\n",
        "  tg_model_group2 = tg_model.layer2\n",
        "  tg_fp2 = tg_model_group2(fp1)\n",
        "  fp2 = tg_fp2\n",
        "  tg_model_group3 = [tg_model.layer3, tg_model.avgpool]\n",
        "  tg_model_group3 = nn.Sequential(*tg_model_group3)\n",
        "  tg_fp3 = tg_model_group3(fp2)\n",
        "  fp3 = tg_fp3\n",
        "  fp3 = fp3.view(fp3.size(0), -1)\n",
        "  if feature_mode:\n",
        "      return fp3\n",
        "  else:\n",
        "      outputs = tg_model.fc(fp3)\n",
        "      feature = fp3\n",
        "      return outputs, feature\n",
        "\n",
        "class mnemonics():\n",
        "  def __init__(self, randomseed):\n",
        "    self.model = resnet32(num_classes=100).to('cuda')\n",
        "    self.feature_extractor = self.model.features\n",
        "    self.lr = 2\n",
        "    self.gamma = 0.2\n",
        "    self.weight_decay = 1e-5 \n",
        "    self.milestones = [49,63]\n",
        "    self.batch_size = 128\n",
        "    self.numepochs = 1\n",
        "    self.n_classes = 0\n",
        "    self.n_known = 0\n",
        "    self.feature_size=64\n",
        "    self.momentum=0.9\n",
        "    self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    self.NUM_BATCHES=10\n",
        "    self.randomseed=randomseed\n",
        "    self.trainloader=None\n",
        "    self.testloader=None\n",
        "    self.CLASSES_PER_BATCH=10\n",
        "    self.original_training_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed)\n",
        "    self.original_test_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed, train=False)\n",
        "    #self.current_training_set = tempDataset()\n",
        "    self.exemplar_sets = []\n",
        "    self.exemplar_labels = []\n",
        "    self.last_test = None\n",
        "    self.y_pred = []\n",
        "    self.y_test = []\n",
        "\n",
        "    self.cumulative_class_mean = []\n",
        "\n",
        "    self.classes_seen=0\n",
        "    self.diz = self.original_training_set.get_dict()\n",
        "\n",
        "    self.mn_exemplar_means = None\n",
        "    # lista di liste, ogni lista contiene gli exemplars di una classe\n",
        "    self.mn_exemplar_sets = [] \n",
        "    # lista di liste, ogni lista contiene le labels dell'elemento corrispondente\n",
        "    self.mn_exemplar_labels = []\n",
        "\n",
        "  def update_params(self, train_data, trainable_params, epochs):\n",
        "    pass\n",
        "\n",
        "  def model_level_optimization(self):\n",
        "    old_model = copy.deepcopy(self.model)\n",
        "    old_model.eval()\n",
        "    old_model.to('cuda')\n",
        "    n_classes = self.classes_seen+self.CLASSES_PER_BATCH\n",
        "    print(n_classes)\n",
        "    optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.milestones, gamma=self.gamma)\n",
        "    for epoch in tqdm(range(self.numepochs)):\n",
        "        \n",
        "      for _, inputs, labels in self.trainloader:\n",
        "        inputs = inputs.float().cuda()\n",
        "        labels = torch.tensor([self.diz[c.item()] for c in labels])\n",
        "\n",
        "        labels=labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        outputs=self.model(inputs)\n",
        "\n",
        "        labels_encoded = F.one_hot(labels,100).float().cuda() #CAMBIARE ONE_HOT\n",
        "        \n",
        "        if self.classes_seen:\n",
        "          old_target = old_model(inputs).cuda()\n",
        "          old_target = torch.sigmoid(old_target).cuda()\n",
        "          \n",
        "          target = torch.cat((old_target[:,:self.classes_seen], labels_encoded[:, self.classes_seen:]), dim=1)\n",
        "          loss = self.criterion(outputs, target)\n",
        "        else:\n",
        "          loss = self.criterion(outputs,labels_encoded) \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "      scheduler.step()\n",
        "\n",
        "  def exemplar_level_optimization(self, new_mn_exemplars):\n",
        "    pass\n",
        "\n",
        "\n",
        "  def classify_nme(self, input_batch):\n",
        "    min_distances = float('inf')*torch.ones(len(input_batch)).cuda() # shape: batch_size --> 128\n",
        "    y_pred = torch.zeros(len(input_batch), dtype=torch.int8).cuda() # shape: batch_size --> 128\n",
        "    input_features = self.model.features(input_batch) # shape: (batch_size, feature_size) --> (128, 64)\n",
        "\n",
        "    for i in range(len(self.exemplar_sets)):\n",
        "      ex_mean = self.exemplar_means[i,:]\n",
        "\n",
        "      # compute distances between inputs features and exemplar set means\n",
        "      pdist = nn.PairwiseDistance(p=2)\n",
        "      distances = pdist(input_features, ex_mean) # shape: batch_size --> 128\n",
        "\n",
        "      # update min distancies and predicted labels\n",
        "      mask = distances < min_distances\n",
        "      min_distances[mask] = distances[mask]\n",
        "      y_pred[mask] = self.exemplar_labels[i]\n",
        "\n",
        "    return y_pred\n",
        "    \n",
        "\n",
        "  def get_new_exemplars(self, batch, m):\n",
        "    loader = torch.utils.data.DataLoader(batch, batch_size=self.batch_size,shuffle=False, num_workers=4)\n",
        "    features = np.zeros((0,self.feature_size))\n",
        "    indices = np.zeros((0), dtype=int)\n",
        "    with torch.no_grad():\n",
        "      for indexes, images, labels in loader:\n",
        "        images = images.cuda()\n",
        "        feature = self.feature_extractor(images).data.cpu().numpy()\n",
        "        feature = normalize(feature, axis=1, norm='l2')\n",
        "        features = np.concatenate((features,feature), axis=0)\n",
        "        indices = np.concatenate((indices,indexes), axis=0)\n",
        "\n",
        "    class_mean = np.mean(features, axis=0)\n",
        "    class_mean = class_mean / np.linalg.norm(class_mean)  # Normalize\n",
        "\n",
        "    self.cumulative_class_mean.append(class_mean)\n",
        "\n",
        "    exemplar_set = []\n",
        "    exemplar_features = np.zeros((0,self.feature_size))\n",
        "\n",
        "    for k in range(1, int(m)+1):\n",
        "        S = np.sum(exemplar_features, axis=0)\n",
        "        phi = features\n",
        "        mu = class_mean\n",
        "        mu_p = 1.0 / k * (phi + S)\n",
        "        mu_p = normalize(mu_p, axis=1, norm='l2')\n",
        "        i = np.argmin(np.sqrt(np.sum((mu - mu_p) ** 2, axis=1)))\n",
        "        exemplar_set.append(indices[i])\n",
        "        addfeature =  np.expand_dims(features[i], axis=0)\n",
        "        exemplar_features = np.concatenate((exemplar_features,addfeature), axis=0)\n",
        "\n",
        "        #remove duplicates\n",
        "        features = np.delete(features, i, 0)\n",
        "        indices = np.delete(indices, i, 0)\n",
        "        \n",
        "    self.exemplar_sets.append(exemplar_set)\n",
        "        \n",
        "  def reduce_old_exemplars(self, m):\n",
        "    for y, P_y in enumerate(self.exemplar_sets):\n",
        "            self.exemplar_sets[y] = P_y[:int(m)]\n",
        "\n",
        "\n",
        "  def __accuracy_fc(self, dl, mapper):\n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    for  _, images, labels in dl:\n",
        "      labels = torch.tensor([torch.tensor(mapper[c.item()]) for c in labels])\n",
        "      labels = labels.cuda()\n",
        "      images = images.cuda()\n",
        "      outputs = self.model(images)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      total += len(labels)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "\n",
        "    acc = correct / total\n",
        "    return acc\n",
        "\n",
        "\n",
        "  def __accuracy_nme(self, dl):\n",
        "    \n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    \n",
        "    for  _, images, labels in dl:\n",
        "      labels = labels.cuda()\n",
        "      images = images.cuda()\n",
        "      preds = self.classify_nme(images)\n",
        "      total += len(labels)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "\n",
        "      if self.last_test:\n",
        "        self.y_pred += preds.tolist()\n",
        "        self.y_test += labels.tolist()\n",
        "\n",
        "    acc = correct / total\n",
        "    return acc\n",
        "\n",
        "\n",
        "  def plot_confusion_matrix(self):\n",
        " \n",
        "    cm = confusion_matrix(self.y_test, self.y_pred)\n",
        "    cm = np.log(cm+1)\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    sns.heatmap(cm, square=True, cbar=False, ax=ax, cmap=plt.get_cmap('seismic'))\n",
        "    ax.set_xticks(np.linspace(19,99,5))\n",
        "    ax.set_yticks(np.linspace(19,99,5))\n",
        "    ax.set_xticklabels([20,40,60,80,100], rotation=0)\n",
        "    ax.set_yticklabels([20,40,60,80,100], rotation=0)\n",
        "    ax.set_title(\"iCaRL\")\n",
        "    ax.set_xlabel(\"Predicted class\")\n",
        "    ax.set_ylabel(\"True class\")\n",
        "    plt.savefig(\"iCaRL_\"+str(self.randomseed)+\"_cm.png\")\n",
        "    plt.show()\n",
        "    return cm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def trainer(self):\n",
        "\n",
        "    train_indices = self.original_training_set.get_batch_indexes()\n",
        "    test_indices = self.original_test_set.get_batch_indexes()\n",
        "    batches=self.original_training_set.getbatches()\n",
        "    current_test_indexes=[]\n",
        "    test_acc = []\n",
        "    self.last_test = False\n",
        "\n",
        "    for i in range(self.NUM_BATCHES):\n",
        "      \n",
        "      if i == self.NUM_BATCHES-1:\n",
        "        self.last_test = True\n",
        "\n",
        "      for exemplar_set in self.exemplar_sets:\n",
        "        train_indices[i]=np.concatenate([train_indices[i], np.array(exemplar_set)])\n",
        "        #print(exemplars)\n",
        "\n",
        "      train_dataset = Subset(self.original_training_set, train_indices[i])\n",
        "      current_test_indexes += test_indices[i].tolist()\n",
        "      test_dataset = Subset(self.original_test_set,current_test_indexes)\n",
        "      self.trainloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "      self.testloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4, drop_last=True)        \n",
        "      self.model.train()\n",
        "      self.model_level_optimization()    \n",
        "      self.classes_seen += 10\n",
        "      #self.model.eval() # Set Network to evaluation mode\n",
        "\n",
        "      # update exemplars number\n",
        "      m=int(2000/(int(i*10+10)))\n",
        "\n",
        "      # reduce the number of each exemplars set\n",
        "      #self.reduce_old_exemplars(m) \n",
        "      \n",
        "      # randomly choose m indexes for each new class and load the corresponding \n",
        "      # data images as mn_exemplars\n",
        "      current_mn_exemplars = [] # 10 classi, m immagini per clasee, dimesioni delle immagini\n",
        "\n",
        "\n",
        "      for classlabel in batches[i]:\n",
        "        indexes_class = self.original_training_set.get_class_indexes(classlabel)\n",
        "        current_class = Subset(self.original_training_set, indexes_class)\n",
        "        #mn_indexes = np.random.choice(indexes_class, size=m, replace=False)\n",
        "        self.get_new_exemplars(current_class, m)\n",
        "        \n",
        "      print(self.original_training_set.dataset.data[1].shape)\n",
        "      self.img_size = 32\n",
        "      self.mnemonics_lrs = 0.01\n",
        "      num_classes_incremental = 10\n",
        "      num_classes = 10\n",
        "      nb_cl = 10\n",
        "      transform_proto = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5071,  0.4866,  0.4409), (0.2009,  0.1984,  0.2023)),])\n",
        "      self.mnemonics_label = []\n",
        "      exemplar_indices = np.array([])\n",
        "      prototypes = np.zeros((10, m, 3, 32, 32))\n",
        "      prototypes_label = np.zeros((10,m))\n",
        "      for xx, exemplar_set in enumerate(self.exemplar_sets[-10:]):\n",
        "        for j, el in enumerate(exemplar_set):\n",
        "          prototypes[xx][j] = self.original_training_set.__getitem__(int(el))[1]\n",
        "          prototypes_label[xx, j] = self.original_training_set.__getitem__(int(el))[2]\n",
        "      \n",
        "        #exemplar_indices = np.concatenate([exemplar_indices, np.array(exemplar_set)])\n",
        "      \n",
        "      #for xx in range(10):\n",
        "       # for j, el in enumerate(exemplar_indices):\n",
        "    \n",
        "      #print()  \n",
        "      self.mnemonics = nn.ParameterList()\n",
        "      self.mnemonics.append(nn.Parameter(torch.Tensor(prototypes)))\n",
        "      print(self.mnemonics[0][0])\n",
        "      device = 'cuda'\n",
        "      self.mnemonics.to(device)\n",
        "      tg_feature_model = nn.Sequential(*list(self.model.children())[:-1])\n",
        "      tg_feature_model.eval()\n",
        "      self.model.eval()\n",
        "\n",
        "      self.mnemonics_optimizer = optim.SGD(self.mnemonics, lr=self.mnemonics_lrs, momentum=0.9, weight_decay=5e-4)\n",
        "      self.mnemonics_lr_scheduler = optim.lr_scheduler.StepLR(self.mnemonics_optimizer, step_size=5, gamma=0.2)\n",
        "      current_means_new = self.cumulative_class_mean\n",
        "      tg_model = self.model\n",
        "      start_iteration = 0\n",
        "      for epoch in range(1):\n",
        "          \n",
        "          train_loss = 0\n",
        "          self.mnemonics_lr_scheduler.step()\n",
        "          for _, q_inputs, q_targets in self.trainloader:\n",
        "              q_targets = torch.tensor([self.diz[c.item()] for c in q_targets])\n",
        "              \n",
        "              q_inputs, q_targets = q_inputs.to(device), q_targets.to(device)\n",
        "              if i == start_iteration:\n",
        "                  q_feature = tg_feature_model(q_inputs)\n",
        "              else:\n",
        "                  q_feature = process_inputs_fp(tg_model, q_inputs, feature_mode=True)\n",
        "              self.mnemonics_optimizer.zero_grad()\n",
        "              total_tr_loss = 0 \n",
        "              if i == start_iteration:\n",
        "                  mnemonics_outputs = tg_feature_model(self.mnemonics[0][0])\n",
        "              else:\n",
        "                  mnemonics_outputs = process_inputs_fp(tg_model, self.mnemonics[0][0], feature_mode=True)\n",
        "              this_class_mean_mnemonics = torch.mean(mnemonics_outputs, dim=0)\n",
        "              this_class_mean_mnemonics = torch.squeeze(this_class_mean_mnemonics)\n",
        "              total_class_mean_mnemonics = this_class_mean_mnemonics.unsqueeze(dim=0)\n",
        "              for mnemonics_idx in range(len(self.mnemonics[0])-1):\n",
        "                  if i == start_iteration:\n",
        "                      mnemonics_outputs = tg_feature_model(self.mnemonics[0][mnemonics_idx+1])\n",
        "                  else:\n",
        "                      mnemonics_outputs = process_inputs_fp(tg_model, self.mnemonics[0][mnemonics_idx+1], feature_mode=True)\n",
        "                  this_class_mean_mnemonics = torch.mean(mnemonics_outputs, dim=0)\n",
        "                  this_class_mean_mnemonics = torch.squeeze(this_class_mean_mnemonics)\n",
        "                  total_class_mean_mnemonics =  torch.cat((total_class_mean_mnemonics, this_class_mean_mnemonics.unsqueeze(dim=0)), dim=0)\n",
        "              if i == start_iteration:\n",
        "                  all_cls_means = total_class_mean_mnemonics\n",
        "              else:\n",
        "                  all_cls_means = torch.tensor(current_means_new).float().to(device)\n",
        "                  all_cls_means[-nb_cl:] = total_class_mean_mnemonics\n",
        "              the_logits = F.linear(F.normalize(torch.squeeze(q_feature), p=2,dim=1), F.normalize(all_cls_means, p=2, dim=1))\n",
        "              loss = F.cross_entropy(the_logits, q_targets)\n",
        "              #loss = nn.CrossEntropyLoss(the_logits, q_targets)\n",
        "              loss.backward()\n",
        "              self.mnemonics_optimizer.step()\n",
        "              train_loss += loss.item()\n",
        "              print('sborro')\n",
        "\n",
        "      print(self.mnemonics[0][0])\n",
        "'''\n",
        "      #PER NME CLASSIFIER\n",
        "      # compute means of exemplar set\n",
        "      # cycle for each exemplar set\n",
        "      self.exemplar_means = torch.zeros((0, self.feature_size), dtype=torch.float).cuda()\n",
        "      self.exemplar_labels = []\n",
        "      for i in range(len(self.exemplar_sets)):\n",
        "        exemplars_dataset = Subset(self.original_training_set, self.exemplar_sets[i])\n",
        "        exemplars_loader = torch.utils.data.DataLoader(exemplars_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
        "        ex_features = torch.zeros((0, self.feature_size), dtype=torch.float).cuda() # alla fine shape: (len(exemplar_set), feature_size) --> (m, 64)\n",
        "      \n",
        "        with torch.no_grad():\n",
        "          _, _, exemplar_label = self.original_training_set.__getitem__(self.exemplar_sets[i][0]) \n",
        "          self.exemplar_labels.append(exemplar_label)\n",
        "          # cycle for each batch in the current exemplar set\n",
        "          for _,  exemplars, _ in exemplars_loader:\n",
        "          \n",
        "            # get exemplars features\n",
        "            exemplars = exemplars.cuda()\n",
        "            features = self.model.features(exemplars) # shape: (len(exemplars), feature_size)\n",
        "          \n",
        "            # normalize \n",
        "            feature_norms = torch.norm(features, p=2, dim=1) # shape: len(exemplars)\n",
        "            feature_norms.unsqueeze_(1) # shape: (len(exemplars), 1)\n",
        "            features = features/feature_norms\n",
        "          \n",
        "            # concatenate over columns\n",
        "            ex_features = torch.cat((ex_features, features), dim=0)\n",
        "          \n",
        "        # compute current exemplar set mean and normalize it\n",
        "        ex_mean = torch.mean(ex_features, dim=0) # shape: feature_size --> 64\n",
        "        ex_mean = ex_mean/torch.norm(ex_mean)\n",
        "        ex_mean.unsqueeze_(0) # shape: (1, feature_size) --> (1, 64)\n",
        "        self.exemplar_means = torch.cat((self.exemplar_means, ex_mean), dim=0) # shape: (n_examplar set, feature size)\n",
        "      \n",
        "\n",
        "      print('accuracy on training set:', 100*self.__accuracy_fc(self.trainloader,self.diz))\n",
        "      # print('accuracy on test set:', self.__accuracy_on(self.testloader,self,self.diz))\n",
        "      current_test_acc = self.__accuracy_nme(self.testloader, last_test)\n",
        "      print('accuracy on test set:', 100*current_test_acc)\n",
        "      print('-' * 80)\n",
        "      test_acc.append(current_test_acc)\n",
        "\n",
        "    # compute comfusion matrix and save results\n",
        "    cm = self.plot_confusion_matrix()\n",
        "    with open('iCaRL_'+str(self.randomseed)+\"_cm\", 'wb') as file:\n",
        "      pickle.dump(cm, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open('iCaRL_'+str(self.randomseed)+\"_testacc\", 'wb') as file:\n",
        "      pickle.dump(test_acc, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n      #PER NME CLASSIFIER\\n      # compute means of exemplar set\\n      # cycle for each exemplar set\\n      self.exemplar_means = torch.zeros((0, self.feature_size), dtype=torch.float).cuda()\\n      self.exemplar_labels = []\\n      for i in range(len(self.exemplar_sets)):\\n        exemplars_dataset = Subset(self.original_training_set, self.exemplar_sets[i])\\n        exemplars_loader = torch.utils.data.DataLoader(exemplars_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)\\n        ex_features = torch.zeros((0, self.feature_size), dtype=torch.float).cuda() # alla fine shape: (len(exemplar_set), feature_size) --> (m, 64)\\n      \\n        with torch.no_grad():\\n          _, _, exemplar_label = self.original_training_set.__getitem__(self.exemplar_sets[i][0]) \\n          self.exemplar_labels.append(exemplar_label)\\n          # cycle for each batch in the current exemplar set\\n          for _,  exemplars, _ in exemplars_loader:\\n          \\n            # get exemplars features\\n            exemplars = exemplars.cuda()\\n            features = self.model.features(exemplars) # shape: (len(exemplars), feature_size)\\n          \\n            # normalize \\n            feature_norms = torch.norm(features, p=2, dim=1) # shape: len(exemplars)\\n            feature_norms.unsqueeze_(1) # shape: (len(exemplars), 1)\\n            features = features/feature_norms\\n          \\n            # concatenate over columns\\n            ex_features = torch.cat((ex_features, features), dim=0)\\n          \\n        # compute current exemplar set mean and normalize it\\n        ex_mean = torch.mean(ex_features, dim=0) # shape: feature_size --> 64\\n        ex_mean = ex_mean/torch.norm(ex_mean)\\n        ex_mean.unsqueeze_(0) # shape: (1, feature_size) --> (1, 64)\\n        self.exemplar_means = torch.cat((self.exemplar_means, ex_mean), dim=0) # shape: (n_examplar set, feature size)\\n      \\n\\n      print(\\'accuracy on training set:\\', 100*self.__accuracy_fc(self.trainloader,self.diz))\\n      # print(\\'accuracy on test set:\\', self.__accuracy_on(self.testloader,self,self.diz))\\n      current_test_acc = self.__accuracy_nme(self.testloader, last_test)\\n      print(\\'accuracy on test set:\\', 100*current_test_acc)\\n      print(\\'-\\' * 80)\\n      test_acc.append(current_test_acc)\\n\\n    # compute comfusion matrix and save results\\n    cm = self.plot_confusion_matrix()\\n    with open(\\'iCaRL_\\'+str(self.randomseed)+\"_cm\", \\'wb\\') as file:\\n      pickle.dump(cm, file, protocol=pickle.HIGHEST_PROTOCOL)\\n    with open(\\'iCaRL_\\'+str(self.randomseed)+\"_testacc\", \\'wb\\') as file:\\n      pickle.dump(test_acc, file, protocol=pickle.HIGHEST_PROTOCOL)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d53e3506b58945b7ba8db19ff786f80e",
            "2f2e6fdfd5a0433784656235d58f597d",
            "99fd10043006459e9cfec3bb2141873c",
            "b04dfe0b5ec64c0b8faf76859a62a3ef",
            "83b87e5600f949199c5f98dce065e05d",
            "a786858e657843dc8d127da53eb0d232",
            "d54d6f7ee6cb418c81732e7a3e44b78c",
            "fb498186ab644d6f88ac46ab4a758714",
            "0f0ada759799428a9d10d14bdb0ec2b8",
            "83697436221d486fa5d8ed3fb2f0f82d",
            "9009c3033812419caae2a4f18b54b0f6",
            "2887d076242147cd9e921f2eb5a15268",
            "13a21820024a47d6ba6137ba50d54644",
            "8d43852428e24dd6aaa5073206b4f821",
            "4024bff1ed2749eea2c7374f25374a2d",
            "31ca7648ceda481db20ffa470e5ae3d9"
          ]
        },
        "id": "OYzLuYGDLr15",
        "outputId": "68d6ebfa-6906-43ef-ce01-f7d283ac7333"
      },
      "source": [
        "model = mnemonics(randomseed=203)\n",
        "model.trainer()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d53e3506b58945b7ba8db19ff786f80e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(32, 32, 3)\n",
            "tensor([[[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-0.2391, -0.0046,  0.1714,  ..., -0.0925,  0.0981,  0.0394],\n",
            "          [-0.1512,  0.0834,  0.2740,  ..., -0.0339,  0.0981,  0.0248],\n",
            "          ...,\n",
            "          [-0.8988, -0.8695, -0.8842,  ..., -1.4266, -1.5439, -1.4266],\n",
            "          [-1.2067, -0.9575, -0.9135,  ..., -1.2507, -1.4999, -1.3826],\n",
            "          [-1.2653, -1.1041, -0.9868,  ..., -1.1920, -1.4119, -1.2946]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-0.0781,  0.1207,  0.2888,  ...,  0.0748,  0.2583,  0.3653],\n",
            "          [ 0.0136,  0.2430,  0.4264,  ...,  0.2888,  0.4876,  0.5487],\n",
            "          ...,\n",
            "          [-1.6681, -1.6528, -1.5458,  ..., -1.5305, -1.2859, -1.1942],\n",
            "          [-1.7293, -1.6681, -1.5152,  ..., -1.5458, -1.2859, -1.1483],\n",
            "          [-1.7293, -1.7140, -1.6834,  ..., -1.5305, -1.1942, -0.9954]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-0.2188, -0.0626,  0.0369,  ..., -0.0483,  0.1647,  0.2499],\n",
            "          [-0.1620,  0.0085,  0.1363,  ...,  0.2783,  0.4914,  0.5482],\n",
            "          ...,\n",
            "          [-1.2840, -1.2698, -1.1846,  ..., -1.4119, -1.3551, -1.3835],\n",
            "          [-1.3693, -1.3125, -1.1562,  ..., -1.3835, -1.3835, -1.3835],\n",
            "          [-1.3977, -1.3551, -1.3125,  ..., -1.3693, -1.3977, -1.3835]]],\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  1.8426,  1.8280,  1.8133],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  1.7986,  1.8280,  1.7986],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -0.4004, -0.7229, -0.7229],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  0.4792,  0.1714,  0.1420],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  0.6552,  0.6991,  0.7724]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  1.9859,  1.9859,  1.9706],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  1.9400,  1.9859,  1.9553],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -0.3839, -0.7508, -0.8425],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  0.5487,  0.2430,  0.1665],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  0.7322,  0.8545,  0.9310]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  2.0254,  2.0111,  2.0111],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  1.9543,  1.9685,  1.9827],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -0.1478, -0.4745, -0.5597],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  0.7044,  0.4488,  0.3920],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  0.8891,  1.0169,  1.1305]]],\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957,  1.3882,  ..., -0.9281, -0.9135, -0.9868],\n",
            "          [-1.8957, -1.8957, -0.6936,  ..., -1.2946, -1.3240, -1.3973],\n",
            "          [-1.8957, -1.8957,  0.4646,  ..., -1.3973, -1.4119, -1.4559],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[-1.8975, -1.8975,  1.4202,  ..., -0.9343, -0.9954, -1.0872],\n",
            "          [-1.8975, -1.8975, -0.0628,  ..., -1.3624, -1.4388, -1.5152],\n",
            "          [-1.8975, -1.8975,  0.9921,  ..., -1.5458, -1.5152, -1.5764],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[-1.5965, -1.5965,  1.4430,  ..., -0.8295, -0.9290, -0.9858],\n",
            "          [-1.5965, -1.5965,  0.2641,  ..., -1.2556, -1.2983, -1.3551],\n",
            "          [-1.5965, -1.5965,  1.1163,  ..., -1.4261, -1.3835, -1.4119],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957,  1.8426,  ...,  1.8426,  1.8426,  1.8426],\n",
            "          [-1.8957, -1.8957,  1.7986,  ...,  1.8280,  1.8280,  1.8426],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957,  1.7840,  ...,  1.8426,  1.8426,  1.8426],\n",
            "          [-1.8957, -1.8957,  1.7840,  ...,  1.8426,  1.8426,  1.8426],\n",
            "          [-1.8957, -1.8957,  1.7986,  ...,  1.8426,  1.8426,  1.8426]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975,  2.0012,  ...,  2.0012,  2.0012,  2.0012],\n",
            "          [-1.8975, -1.8975,  1.9553,  ...,  1.9859,  1.9859,  2.0012],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975,  1.9247,  ...,  2.0012,  2.0012,  2.0012],\n",
            "          [-1.8975, -1.8975,  1.9400,  ...,  2.0012,  2.0012,  2.0012],\n",
            "          [-1.8975, -1.8975,  1.9553,  ...,  2.0012,  2.0012,  2.0012]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965,  2.0254,  ...,  2.0254,  2.0254,  2.0254],\n",
            "          [-1.5965, -1.5965,  1.9827,  ...,  2.0111,  2.0111,  2.0254],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965,  1.9685,  ...,  2.0254,  2.0254,  2.0254],\n",
            "          [-1.5965, -1.5965,  1.9685,  ...,  2.0254,  2.0254,  2.0254],\n",
            "          [-1.5965, -1.5965,  1.9827,  ...,  2.0254,  2.0254,  2.0254]]],\n",
            "\n",
            "\n",
            "        [[[-0.2538, -0.2245, -0.4883,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-0.3857, -0.5177, -0.8109,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-0.5910, -0.8842, -0.9721,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[ 0.0442,  0.0442, -0.2310,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-0.0475, -0.2310, -0.5826,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-0.3380, -0.7814, -0.8578,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[-0.7443, -0.6307, -0.8153,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-0.9432, -0.8721, -1.0426,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.0000, -0.8864, -1.0142,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.3386, -1.3093, -1.3240,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          ...,\n",
            "          [ 0.9630,  0.6991,  0.6845,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [ 1.0510,  0.6258,  0.3619,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [ 0.9337,  0.2740,  0.5525,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-0.4909, -0.4756, -0.4756,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          ...,\n",
            "          [ 0.8698,  0.5946,  0.5487,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [ 0.9615,  0.5182,  0.2430,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [ 0.8239,  0.1359,  0.4111,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [ 0.3209,  0.3351,  0.3209,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          ...,\n",
            "          [ 1.4856,  1.2300,  1.1589,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [ 1.5566,  1.1447,  0.9317,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [ 1.4004,  0.7470,  1.0027,  ..., -1.5965, -1.5965, -1.5965]]]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "tensor([[[[-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-0.2388, -0.0045,  0.1711,  ..., -0.0924,  0.0979,  0.0394],\n",
            "          [-0.1509,  0.0833,  0.2736,  ..., -0.0338,  0.0979,  0.0247],\n",
            "          ...,\n",
            "          [-0.8975, -0.8682, -0.8828,  ..., -1.4244, -1.5415, -1.4244],\n",
            "          [-1.2049, -0.9560, -0.9121,  ..., -1.2488, -1.4976, -1.3805],\n",
            "          [-1.2634, -1.1024, -0.9853,  ..., -1.1902, -1.4098, -1.2927]],\n",
            "\n",
            "         [[-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-0.0780,  0.1205,  0.2884,  ...,  0.0747,  0.2579,  0.3647],\n",
            "          [ 0.0136,  0.2426,  0.4258,  ...,  0.2884,  0.4868,  0.5479],\n",
            "          ...,\n",
            "          [-1.6656, -1.6504, -1.5435,  ..., -1.5282, -1.2840, -1.1924],\n",
            "          [-1.7267, -1.6656, -1.5130,  ..., -1.5435, -1.2840, -1.1466],\n",
            "          [-1.7267, -1.7114, -1.6809,  ..., -1.5282, -1.1924, -0.9939]],\n",
            "\n",
            "         [[-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-0.2185, -0.0625,  0.0368,  ..., -0.0483,  0.1645,  0.2495],\n",
            "          [-0.1617,  0.0085,  0.1361,  ...,  0.2779,  0.4906,  0.5474],\n",
            "          ...,\n",
            "          [-1.2821, -1.2679, -1.1828,  ..., -1.4098, -1.3530, -1.3814],\n",
            "          [-1.3672, -1.3105, -1.1545,  ..., -1.3814, -1.3814, -1.3814],\n",
            "          [-1.3956, -1.3530, -1.3105,  ..., -1.3672, -1.3956, -1.3814]]],\n",
            "\n",
            "\n",
            "        [[[-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928, -1.8928,  ...,  1.8398,  1.8252,  1.8106],\n",
            "          [-1.8928, -1.8928, -1.8928,  ...,  1.7959,  1.8252,  1.7959],\n",
            "          ...,\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -0.3998, -0.7218, -0.7218],\n",
            "          [-1.8928, -1.8928, -1.8928,  ...,  0.4785,  0.1711,  0.1418],\n",
            "          [-1.8928, -1.8928, -1.8928,  ...,  0.6542,  0.6981,  0.7713]],\n",
            "\n",
            "         [[-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946, -1.8946,  ...,  1.9829,  1.9829,  1.9676],\n",
            "          [-1.8946, -1.8946, -1.8946,  ...,  1.9371,  1.9829,  1.9524],\n",
            "          ...,\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -0.3833, -0.7497, -0.8413],\n",
            "          [-1.8946, -1.8946, -1.8946,  ...,  0.5479,  0.2426,  0.1663],\n",
            "          [-1.8946, -1.8946, -1.8946,  ...,  0.7311,  0.8532,  0.9296]],\n",
            "\n",
            "         [[-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941, -1.5941,  ...,  2.0223,  2.0081,  2.0081],\n",
            "          [-1.5941, -1.5941, -1.5941,  ...,  1.9514,  1.9656,  1.9798],\n",
            "          ...,\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -0.1475, -0.4737, -0.5588],\n",
            "          [-1.5941, -1.5941, -1.5941,  ...,  0.7034,  0.4481,  0.3914],\n",
            "          [-1.5941, -1.5941, -1.5941,  ...,  0.8877,  1.0154,  1.1288]]],\n",
            "\n",
            "\n",
            "        [[[-1.8928, -1.8928,  1.3861,  ..., -0.9267, -0.9121, -0.9853],\n",
            "          [-1.8928, -1.8928, -0.6925,  ..., -1.2927, -1.3220, -1.3952],\n",
            "          [-1.8928, -1.8928,  0.4639,  ..., -1.3952, -1.4098, -1.4537],\n",
            "          ...,\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928]],\n",
            "\n",
            "         [[-1.8946, -1.8946,  1.4181,  ..., -0.9329, -0.9939, -1.0855],\n",
            "          [-1.8946, -1.8946, -0.0627,  ..., -1.3603, -1.4366, -1.5130],\n",
            "          [-1.8946, -1.8946,  0.9906,  ..., -1.5435, -1.5130, -1.5740],\n",
            "          ...,\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946]],\n",
            "\n",
            "         [[-1.5941, -1.5941,  1.4408,  ..., -0.8283, -0.9276, -0.9843],\n",
            "          [-1.5941, -1.5941,  0.2637,  ..., -1.2537, -1.2963, -1.3530],\n",
            "          [-1.5941, -1.5941,  1.1147,  ..., -1.4239, -1.3814, -1.4098],\n",
            "          ...,\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928,  1.8398,  ...,  1.8398,  1.8398,  1.8398],\n",
            "          [-1.8928, -1.8928,  1.7959,  ...,  1.8252,  1.8252,  1.8398],\n",
            "          ...,\n",
            "          [-1.8928, -1.8928,  1.7813,  ...,  1.8398,  1.8398,  1.8398],\n",
            "          [-1.8928, -1.8928,  1.7813,  ...,  1.8398,  1.8398,  1.8398],\n",
            "          [-1.8928, -1.8928,  1.7959,  ...,  1.8398,  1.8398,  1.8398]],\n",
            "\n",
            "         [[-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946,  1.9982,  ...,  1.9982,  1.9982,  1.9982],\n",
            "          [-1.8946, -1.8946,  1.9524,  ...,  1.9829,  1.9829,  1.9982],\n",
            "          ...,\n",
            "          [-1.8946, -1.8946,  1.9218,  ...,  1.9982,  1.9982,  1.9982],\n",
            "          [-1.8946, -1.8946,  1.9371,  ...,  1.9982,  1.9982,  1.9982],\n",
            "          [-1.8946, -1.8946,  1.9524,  ...,  1.9982,  1.9982,  1.9982]],\n",
            "\n",
            "         [[-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941,  2.0223,  ...,  2.0223,  2.0223,  2.0223],\n",
            "          [-1.5941, -1.5941,  1.9798,  ...,  2.0081,  2.0081,  2.0223],\n",
            "          ...,\n",
            "          [-1.5941, -1.5941,  1.9656,  ...,  2.0223,  2.0223,  2.0223],\n",
            "          [-1.5941, -1.5941,  1.9656,  ...,  2.0223,  2.0223,  2.0223],\n",
            "          [-1.5941, -1.5941,  1.9798,  ...,  2.0223,  2.0223,  2.0223]]],\n",
            "\n",
            "\n",
            "        [[[-0.2534, -0.2241, -0.4876,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-0.3851, -0.5169, -0.8096,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-0.5901, -0.8828, -0.9707,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          ...,\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928]],\n",
            "\n",
            "         [[ 0.0441,  0.0441, -0.2306,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-0.0475, -0.2306, -0.5818,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-0.3375, -0.7802, -0.8565,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          ...,\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946]],\n",
            "\n",
            "         [[-0.7432, -0.6297, -0.8141,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-0.9417, -0.8708, -1.0410,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-0.9985, -0.8850, -1.0127,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          ...,\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941]]],\n",
            "\n",
            "\n",
            "        [[[-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.8928, -1.8928, -1.8928,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [-1.3366, -1.3073, -1.3220,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          ...,\n",
            "          [ 0.9616,  0.6981,  0.6834,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [ 1.0494,  0.6249,  0.3614,  ..., -1.8928, -1.8928, -1.8928],\n",
            "          [ 0.9323,  0.2736,  0.5517,  ..., -1.8928, -1.8928, -1.8928]],\n",
            "\n",
            "         [[-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-1.8946, -1.8946, -1.8946,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [-0.4902, -0.4749, -0.4749,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          ...,\n",
            "          [ 0.8685,  0.5937,  0.5479,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [ 0.9601,  0.5174,  0.2426,  ..., -1.8946, -1.8946, -1.8946],\n",
            "          [ 0.8227,  0.1357,  0.4105,  ..., -1.8946, -1.8946, -1.8946]],\n",
            "\n",
            "         [[-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [-1.5941, -1.5941, -1.5941,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [ 0.3205,  0.3346,  0.3205,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          ...,\n",
            "          [ 1.4834,  1.2281,  1.1572,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [ 1.5543,  1.1430,  0.9303,  ..., -1.5941, -1.5941, -1.5941],\n",
            "          [ 1.3983,  0.7459,  1.0012,  ..., -1.5941, -1.5941, -1.5941]]]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f0ada759799428a9d10d14bdb0ec2b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(32, 32, 3)\n",
            "tensor([[[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -0.8109, -0.9575, -1.5439],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -0.4883, -0.3857, -0.9721],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  0.2300, -0.2538, -0.5323]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.1330, -1.2706, -1.6070],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -0.7508, -0.5673, -1.0566],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -0.0628, -0.7049, -0.7814]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -0.8011, -0.9574, -1.3551],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -0.3466, -0.2330, -0.7869],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  0.1931, -0.5739, -0.5597]]],\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [ 1.3882,  1.7253,  1.7986,  ..., -0.1218, -0.0632, -1.8957],\n",
            "          [ 1.3735,  1.7107,  1.6960,  ..., -0.2098, -0.1805, -1.8957],\n",
            "          ...,\n",
            "          [ 0.5819,  1.0656,  1.0217,  ...,  0.4353,  0.3766, -1.8957],\n",
            "          [ 0.0394,  0.8164,  0.8457,  ...,  0.4646,  0.1714, -1.8957],\n",
            "          [ 0.2153,  0.5525,  0.4353,  ...,  0.2593, -0.0192, -1.8957]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [ 1.5272,  1.8941,  2.0012,  ..., -0.2004, -0.2310, -1.8975],\n",
            "          [ 1.5119,  1.8789,  1.8636,  ..., -0.2921, -0.3839, -1.8975],\n",
            "          ...,\n",
            "          [-0.0628,  0.2888,  0.3194,  ...,  0.6252,  0.4417, -1.8975],\n",
            "          [-0.5062,  0.1665,  0.3041,  ...,  0.5640,  0.1359, -1.8975],\n",
            "          [-0.2921, -0.0475, -0.0628,  ...,  0.2735, -0.1393, -1.8975]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [ 1.5424,  1.9117,  2.0111,  ..., -0.7017, -0.7017, -1.5965],\n",
            "          [ 1.5282,  1.8691,  1.8691,  ..., -1.0710, -1.1136, -1.5965],\n",
            "          ...,\n",
            "          [ 0.4346,  0.7186,  0.6618,  ...,  1.0595,  0.9033, -1.5965],\n",
            "          [-0.0483,  0.5340,  0.5766,  ...,  1.0453,  0.6476, -1.5965],\n",
            "          [ 0.0653,  0.2357,  0.1221,  ...,  0.8323,  0.4204, -1.5965]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8426,  1.8426,  1.8426,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [ 1.8426,  1.8426,  1.8426,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [ 1.8426,  1.8426,  1.8426,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          ...,\n",
            "          [-0.0925,  0.2300,  0.4646,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[ 2.0012,  2.0012,  2.0012,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [ 2.0012,  2.0012,  2.0012,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [ 2.0012,  2.0012,  2.0012,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          ...,\n",
            "          [-0.1240,  0.2277,  0.4570,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[ 2.0254,  2.0254,  2.0254,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [ 2.0254,  2.0254,  2.0254,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [ 2.0254,  2.0254,  2.0254,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          ...,\n",
            "          [-0.0483,  0.2783,  0.5340,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957, -1.8957,  ...,  1.4321,  1.5494,  1.5787],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  1.4908,  1.6081,  1.6081],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  1.4761,  1.5348,  1.4908],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  0.8897,  0.8457,  0.9044],\n",
            "          [-1.8957, -1.8957, -1.8957,  ...,  1.1243,  1.0070,  0.9337],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ...,  1.6342,  1.7718,  1.8024],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  1.6954,  1.8177,  1.8330],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  1.6954,  1.7565,  1.7107],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  0.9768,  0.9310,  0.9921],\n",
            "          [-1.8975, -1.8975, -1.8975,  ...,  1.1756,  1.0686,  0.9921],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ...,  1.7271,  1.8549,  1.8691],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  1.7839,  1.8975,  1.8975],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  1.7839,  1.8265,  1.7839],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  1.2868,  1.2442,  1.3010],\n",
            "          [-1.5965, -1.5965, -1.5965,  ...,  1.5708,  1.4714,  1.4004],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
            "\n",
            "\n",
            "        [[[-1.8957, -1.8957, -1.8957,  ..., -0.0925, -0.0046,  0.0394],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -0.1805, -0.0632,  0.0248],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -0.2978, -0.1072, -0.0192],\n",
            "          ...,\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[-1.8975, -1.8975, -1.8975,  ..., -0.0781,  0.0136,  0.0595],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -0.1851, -0.0475,  0.0136],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -0.2921, -0.1240, -0.0169],\n",
            "          ...,\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[-1.5965, -1.5965, -1.5965,  ..., -0.0057,  0.0795,  0.1221],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -0.1052,  0.0227,  0.1079],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -0.2046, -0.0341,  0.0653],\n",
            "          ...,\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
            "\n",
            "\n",
            "        [[[-1.8371, -1.8371, -1.8224,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8371, -1.8371, -1.8224,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8371, -1.8371, -1.8371,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          ...,\n",
            "          [ 1.4908,  1.6374,  1.6227,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
            "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
            "\n",
            "         [[-1.8363, -1.8363, -1.8210,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8363, -1.8363, -1.8210,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8363, -1.8363, -1.8363,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          ...,\n",
            "          [ 1.6342,  1.7871,  1.7718,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
            "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
            "\n",
            "         [[-1.5397, -1.5397, -1.5255,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5397, -1.5397, -1.5255,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5397, -1.5397, -1.5397,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          ...,\n",
            "          [ 1.6845,  1.8265,  1.8123,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
            "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n",
            "sborro\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4650da49505f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnemonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m203\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-a762099ef573>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m               \u001b[0;31m#loss = nn.CrossEntropyLoss(the_logits, q_targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m               \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnemonics_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m               \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}