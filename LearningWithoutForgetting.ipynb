{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningWithoutForgetting.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjYCGvtRICO5mrc3mxa2WF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandronicolini/IncrementalLearning/blob/main/LearningWithoutForgetting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9nP5BV_m16C",
        "outputId": "f8d86703-2bd6-4fcf-cb05-ca915fe750a8"
      },
      "source": [
        "# upload work files from your git hub repository\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/alessandronicolini/IncrementalLearning.git # clone proj repository\n",
        "!rm -rf IncrementalLearning/README.md \n",
        "!rm -rf IncrementalLearning/baselines.ipynb\n",
        "\n",
        "path = 'IncrementalLearning/'\n",
        "if path not in sys.path:\n",
        "    sys.path.append('IncrementalLearning/')\n",
        "\n",
        "!pip3 install import_ipynb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'IncrementalLearning' already exists and is not an empty directory.\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R41rvWGamroV"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import import_ipynb\n",
        "import copy\n",
        "# project classes --------------------------------------------------------------\n",
        "from cifar100 import ilCIFAR100\n",
        "from resnet_cifar import resnet32"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD1W9sXOnEHg"
      },
      "source": [
        "class lwf(nn.Module):\n",
        "  def __init__(self,network):\n",
        "    super(lwf, self).__init__()\n",
        "    self.model=network\n",
        "    self.batch_size=128\n",
        "    self.CLASSES_PER_BATCH=10\n",
        "    self.NUM_BATCHES=10\n",
        "    self.LR=2\n",
        "    self.MOMENTUM=0.9\n",
        "    self.WEIGHT_DECAY=1e-5\n",
        "    self.MILESTONES=[49,63]\n",
        "    self.GAMMA=0.2\n",
        "    self.numepochs=70\n",
        "    self.randomseed=10\n",
        "    self.trainloader=None\n",
        "    self.testloader=None\n",
        "    self.original_training_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed)\n",
        "    self.original_test_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed, train=False)\n",
        "    self.criterion=nn.BCEWithLogitsLoss()\n",
        "    self.optimizer = optim.SGD(self.model.parameters(), lr=self.LR, momentum=self.MOMENTUM, weight_decay=self.WEIGHT_DECAY)\n",
        "    self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.MILESTONES, gamma=self.GAMMA)\n",
        "    self.firstbatch=1\n",
        "    self.classes_seen=0\n",
        "  def update_parameters(self):\n",
        "    old_model = copy.deepcopy(self)\n",
        "    old_model.eval()\n",
        "    old_model.to('cuda')\n",
        "    for epoch in range(self.numepochs):\n",
        "      #print(epoch)\n",
        "        \n",
        "        for inputs,labels in self.train_loader:\n",
        "          labels = torch.tensor([torch.tensor(diz[c.item()]) for c in labels])\n",
        "          inputs=inputs.to('cuda')\n",
        "          labels=labels.to('cuda')\n",
        "          self.optimizer.zero_grad()\n",
        "          outputs=self.model(inputs)\n",
        "\n",
        "          labels_encoded=torch.eye(100)[labels] #CAMBIARE ONE_HOT\n",
        "          labels_encoded=labels_encoded.to('cuda')\n",
        "          if self.firstbatch:\n",
        "            loss=self.criterion(outputs[:,:self.batch_size],labels_encoded)\n",
        "          else:\n",
        "            old_target=old_model(inputs)\n",
        "            target = torch.cat((old_target[:,:self.classes_seen],labels_encoded [:, self.classes_seen:self.classes_seen+self.batch_size]), dim=1)\n",
        "            loss=self.criterion(outputs[:,:self.classes_seen+self.batch_size],target)\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "        self.scheduler.step()\n",
        "\n",
        "        \n",
        "              # deep copy the model\n",
        "  def training(self):\n",
        "    \n",
        "    train_indices = self.original_training_set.get_batch_indexes()\n",
        "    test_indices = self.original_test_set.get_batch_indexes()\n",
        "    current_test_indexes=[]\n",
        "    \n",
        "    diz = self.original_training_set.get_dict()\n",
        "    acc=[]\n",
        "    accuracy=0\n",
        "    for i in range(self.NUM_BATCHES):\n",
        "  \n",
        "      train_dataset=Subset(self.original_training_set,train_indices[i])\n",
        "      current_test_indexes+=test_indices[i].tolist()\n",
        "      test_dataset=Subset(self.original_test_set,current_test_indexes)\n",
        "      self.trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "      self.testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)        \n",
        "      self.train()\n",
        "      self.update()\n",
        "      self.firstbatch=0\n",
        "      self.classes_seen+=10\n",
        "      self.train(False) # Set Network to evaluation mode\n",
        "      running_corrects = 0\n",
        "      y_true = []\n",
        "      y_pred = []\n",
        "      for inputs, labels in test_dataloader:\n",
        "          labels = torch.tensor([torch.tensor(diz[c.item()]) for c in labels])\n",
        "          inputs = inputs.to('cuda')\n",
        "          labels = labels.to('cuda')\n",
        "          outputs = self.model(inputs)\n",
        "          _, preds = torch.max(outputs.data, 1)\n",
        "          running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "          labels=labels.detach().cpu().numpy()\n",
        "          labels=labels.tolist()\n",
        "          y_true.extend(labels)\n",
        "          preds=preds.detach().cpu().numpy()\n",
        "          y_pred_tmp = [p for p in preds]\n",
        "          y_pred.extend(y_pred_tmp)\n",
        "      accuracy = running_corrects / float(len(test_dataloader.dataset))\n",
        "      print('Test Accuracy: %.2f' % (100.0 * accuracy))\n",
        "      print('-' * 80)\n",
        "      acc.append(accuracy)\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b6XwdKK6Kqd",
        "outputId": "19fdaddb-e159-4ff1-827a-77569c085c61"
      },
      "source": [
        "model=lwf(network=resnet32(num_classes=100))\n",
        "model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "[73, 4, 54, 61, 99, 1, 26, 59, 62, 35, 83, 20, 98, 66, 91, 41, 9, 31, 46, 5, 53, 17, 77, 45, 48, 79, 36, 33, 58, 22, 38, 81, 78, 71, 30, 56, 75, 2, 37, 0, 15, 8, 12, 19, 34, 23, 49, 92, 88, 42, 90, 28, 27, 65, 87, 84, 96, 51, 32, 10, 14, 93, 52, 85, 95, 82, 64, 76, 80, 44, 57, 18, 11, 72, 68, 3, 24, 39, 55, 6, 47, 13, 63, 70, 7, 40, 25, 74, 89, 86, 29, 94, 67, 97, 69, 16, 43, 60, 50, 21]\n",
            "Files already downloaded and verified\n",
            "[73, 4, 54, 61, 99, 1, 26, 59, 62, 35, 83, 20, 98, 66, 91, 41, 9, 31, 46, 5, 53, 17, 77, 45, 48, 79, 36, 33, 58, 22, 38, 81, 78, 71, 30, 56, 75, 2, 37, 0, 15, 8, 12, 19, 34, 23, 49, 92, 88, 42, 90, 28, 27, 65, 87, 84, 96, 51, 32, 10, 14, 93, 52, 85, 95, 82, 64, 76, 80, 44, 57, 18, 11, 72, 68, 3, 24, 39, 55, 6, 47, 13, 63, 70, 7, 40, 25, 74, 89, 86, 29, 94, 67, 97, 69, 16, 43, 60, 50, 21]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lwf(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=64, out_features=100, bias=True)\n",
              "  )\n",
              "  (criterion): BCEWithLogitsLoss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "CeWOGxlV6Rrw",
        "outputId": "9d31cb63-23c4-42d3-a2c1-b3d7195eb5b0"
      },
      "source": [
        "model=model.training()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f9cf81d50cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPHXgeDP7jWC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}