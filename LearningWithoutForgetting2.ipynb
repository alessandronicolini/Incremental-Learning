{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LearningWithoutForgetting.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandronicolini/IncrementalLearning/blob/main/LearningWithoutForgetting2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9nP5BV_m16C"
      },
      "source": [
        "# upload work files from your git hub repository\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/alessandronicolini/IncrementalLearning.git # clone proj repository\n",
        "!rm -rf IncrementalLearning/README.md \n",
        "!rm -rf IncrementalLearning/baselines.ipynb\n",
        "\n",
        "path = 'IncrementalLearning/'\n",
        "if path not in sys.path:\n",
        "    sys.path.append('IncrementalLearning/')\n",
        "\n",
        "!pip3 install import_ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R41rvWGamroV"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import import_ipynb\n",
        "import copy\n",
        "# project classes --------------------------------------------------------------\n",
        "from IncrementalLearning.cifar100 import ilCIFAR100\n",
        "from resnet_cifar import resnet32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD1W9sXOnEHg"
      },
      "source": [
        "class lwf(nn.Module):\n",
        "  def __init__(self,network, random_seed, batch_size):\n",
        "    super(lwf, self).__init__()\n",
        "    \n",
        "    self.batch_size = batch_size\n",
        "    self.classes_per_task=10\n",
        "    self.num_tasks=10\n",
        "    self.LR=2\n",
        "    self.MOMENTUM=0.9\n",
        "    self.WEIGHT_DECAY=1e-5\n",
        "    self.MILESTONES=[49,63]\n",
        "    self.GAMMA=0.2\n",
        "    self.numepochs=70\n",
        "    \n",
        "    self.original_training_set = ilCIFAR100(self.classes_per_task, random_seed)\n",
        "    self.original_test_set = ilCIFAR100(self.classes_per_task, random_seed, train=False)\n",
        "    \n",
        "    self.model = network.to('cuda')\n",
        "    self.criterion = nn.BCEWithLogitsLoss()\n",
        "    self.optimizer = optim.SGD(self.model.parameters(), lr=self.LR, momentum=self.MOMENTUM, weight_decay=self.WEIGHT_DECAY)\n",
        "    self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.MILESTONES, gamma=self.GAMMA)\n",
        "    \n",
        "    self.diz = self.original_training_set.get_dict()\n",
        "    self.task_counter = -1\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.model = self.model.cuda()\n",
        "    return self.model.forward(x)\n",
        "\n",
        "  def update_parameters(self, train_dataloader):\n",
        "\n",
        "    self.task_counter += 1 # new incoming task is starting\n",
        "    old_model = copy.deepcopy(self)\n",
        "    old_model.eval()\n",
        "    old_model.to('cuda')\n",
        "\n",
        "    for epoch in range(self.numepochs):\n",
        "      for inputs,labels in train_dataloader:\n",
        "        labels = torch.tensor([torch.tensor(self.diz[c.item()]) for c in labels])\n",
        "        inputs=inputs.to('cuda')\n",
        "        labels=labels.to('cuda')\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs=self.model(inputs)\n",
        "\n",
        "        new_target=torch.eye(100)[labels] \n",
        "        new_target=new_target.to('cuda')\n",
        "\n",
        "        if self.task_counter == 0:\n",
        "          loss=self.criterion(outputs,new_target)\n",
        "        \n",
        "        else:\n",
        "          seen_classes = self.task_counter*self.classes_per_task\n",
        "          #current_classes = seen_classes + self.classes_per_task\n",
        "\n",
        "          old_target=old_model(inputs)\n",
        "          old_target=torch.sigmoid(old_target).cuda()\n",
        "          target = torch.cat((old_target[:,:seen_classes], new_target[:, seen_classes:]), dim=1)\n",
        "          loss=self.criterion(outputs,target)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "      self.scheduler.step()\n",
        "\n",
        "        \n",
        "  # deep copy the model\n",
        "  def training_lwf(self):\n",
        "    \n",
        "    train_indices = self.original_training_set.get_batch_indexes()\n",
        "    test_indices = self.original_test_set.get_batch_indexes()\n",
        "    current_test_indexes=[]\n",
        "    \n",
        "    #diz = self.original_training_set.get_dict()\n",
        "    acc=[]\n",
        "    accuracy=0\n",
        "\n",
        "    for i in range(self.num_tasks):\n",
        "      train_dataset = Subset(self.original_training_set,train_indices[i])\n",
        "      current_test_indexes += test_indices[i].tolist()\n",
        "      test_dataset = Subset(self.original_test_set,current_test_indexes)\n",
        "      train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "      test_dataloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True)        \n",
        "      self.train()\n",
        "      self.update_parameters(train_dataloader)\n",
        "      self.train(False) # Set Network to evaluation mode\n",
        "      running_corrects = 0\n",
        "      y_true = []\n",
        "      y_pred = []\n",
        "      for inputs, labels in test_dataloader:\n",
        "          labels = torch.tensor([torch.tensor(self.diz[c.item()]) for c in labels])\n",
        "          inputs = inputs.to('cuda')\n",
        "          labels = labels.to('cuda')\n",
        "          outputs = self.model(inputs)\n",
        "          _, preds = torch.max(outputs.data, 1)\n",
        "          running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "          labels=labels.detach().cpu().numpy()\n",
        "          labels=labels.tolist()\n",
        "          y_true.extend(labels)\n",
        "          preds=preds.detach().cpu().numpy()\n",
        "          y_pred_tmp = [p for p in preds]\n",
        "          y_pred.extend(y_pred_tmp)\n",
        "      accuracy = running_corrects / float(len(test_dataloader.dataset))\n",
        "      print('Test Accuracy: %.2f' % (100.0 * accuracy))\n",
        "      print('-' * 80)\n",
        "      acc.append(accuracy)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b6XwdKK6Kqd"
      },
      "source": [
        "lwf(network=resnet32(num_classes=100), batch_size = 128, random_seed = 10).training_lwf()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}