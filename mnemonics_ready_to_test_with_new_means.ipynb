{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnemonics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "259c7293bcf149739326b5920e351742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ef89a0753bb4e539c609d79c31207bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2cc74e49a75495c80b2ae28a65ea889",
              "IPY_MODEL_b4a7fe27aca84913ab171db5a589737f"
            ]
          }
        },
        "8ef89a0753bb4e539c609d79c31207bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2cc74e49a75495c80b2ae28a65ea889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6925bddeeeeb4012b2f07f81900fd9ad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86665b3332cb47c0b49eadc4a412485c"
          }
        },
        "b4a7fe27aca84913ab171db5a589737f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_878f69bcc6ed4094acd811bf2f60d052",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:18&lt;00:00, 18.05s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04c44032756b4f2cacd33959bcc3c554"
          }
        },
        "6925bddeeeeb4012b2f07f81900fd9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86665b3332cb47c0b49eadc4a412485c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "878f69bcc6ed4094acd811bf2f60d052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04c44032756b4f2cacd33959bcc3c554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00e27416b0e5401f9ae04d528cdf3242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99ebb9bed54442b0bb5a9c47b759fd34",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_674dab1540724fc895a3eac3e9d132b2",
              "IPY_MODEL_cf7435b0a4c94f80afe2d726c52c9604"
            ]
          }
        },
        "99ebb9bed54442b0bb5a9c47b759fd34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "674dab1540724fc895a3eac3e9d132b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5260d34bf31740a899b508343e17429f",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea33477caf6042998a2b1c77410e06e6"
          }
        },
        "cf7435b0a4c94f80afe2d726c52c9604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_878f6240835744ca92eeaf5f6664805b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_955bef1d2d0a44b186aa0497a5ed417c"
          }
        },
        "5260d34bf31740a899b508343e17429f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea33477caf6042998a2b1c77410e06e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "878f6240835744ca92eeaf5f6664805b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "955bef1d2d0a44b186aa0497a5ed417c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandronicolini/IncrementalLearning/blob/main/mnemonics_ready_to_test_with_new_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH7YHXeh0hFj",
        "outputId": "83b7209c-bbff-41c5-9b97-e3b0356926aa"
      },
      "source": [
        "!pip3 install 'import_ipynb'\n",
        "!pip3 install 'tqdm'\n",
        " \n",
        "!rm -r IncrementalLearning\n",
        "# upload work files from your git hub repository\n",
        "import sys\n",
        " \n",
        "!git clone https://github.com/alessandronicolini/IncrementalLearning.git # clone proj repository\n",
        "!rm -rf IncrementalLearning/README.md \n",
        "!rm -rf IncrementalLearning/baselines.ipynb\n",
        " \n",
        "path = 'IncrementalLearning/'\n",
        "if path not in sys.path:\n",
        "    sys.path.append('IncrementalLearning/')\n",
        " \n",
        "!pip3 install import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 577 (delta 65), reused 0 (delta 0), pack-reused 474\u001b[K\n",
            "Receiving objects: 100% (577/577), 652.60 KiB | 12.08 MiB/s, done.\n",
            "Resolving deltas: 100% (340/340), done.\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEF9KBox0cAd"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "import random\n",
        "import torchvision\n",
        "ROOT = './data'\n",
        "class ilCIFAR100(VisionDataset):\n",
        "    \"\"\"\n",
        "    Extends CIFAR100 class. Split the dataset into 10 batches, each one containing 10 classes.\n",
        "    You can retrieve the batches from the attribute \"batches\", it has different structure according to\n",
        "    test and train CIFAR100 splits:\n",
        "        - train -> batches is a dictionary {0:{'train':indexes, 'val':indexes}...} \n",
        "        - test -> batches is a dictionary {0:indexes...}\n",
        "    where the keys are the batch number.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where directory\n",
        "            `cifar-10-batches-py` exists or will be saved to if download is set to True.\n",
        "        seed(int): used to ensure reproducibility in shuffling operations.\n",
        "        val_size(float, optional): between 0 and 1, fraction of data used for validation.\n",
        "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
        "            creates from test set.\n",
        "        transform (callable, optional): A function/transform that takes in an PIL image\n",
        "            and returns a transformed version. E.g, `transforms.RandomCrop`\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "    \"\"\"\n",
        "    def __init__(self,classes_per_batch, seed, val_size=0.1, train=True, transform=None, target_transform=False, \n",
        "    download=True):\n",
        "        \n",
        "        super(ilCIFAR100, self).__init__(root=0)\n",
        "        self.classes_per_batch=classes_per_batch\n",
        "\n",
        "        \n",
        "        self.__rs = seed # set random seed \n",
        "        self.train=train\n",
        "        self.__transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "        ])\n",
        "\n",
        "        self.__transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "        ])\n",
        "        # if train:\n",
        "        #     self.batches = self.__make_train_batches(val_size)\n",
        "        # else:\n",
        "        #     self.batches = self.__make_test_batches()\n",
        "        if self.train == 'train':\n",
        "          self.dataset = torchvision.datasets.CIFAR100(root=ROOT, train=True,\n",
        "                                            download=True, transform=self.__transform_train)\n",
        "        elif self.train == 'exemplars':\n",
        "          self.dataset = torchvision.datasets.CIFAR100(root=ROOT, train=True,\n",
        "                                            download=True, transform=self.__transform_test)\n",
        "        else:\n",
        "          self.dataset = torchvision.datasets.CIFAR100(root=ROOT, train=False,\n",
        "                                        download=True, transform=self.__transform_test)\n",
        "          \n",
        "        self.targets = np.array(self.dataset.targets) # make targets an array to exploit masking\n",
        "        random.seed(seed)\n",
        "        self.classes = random.sample(range(0, 100), 100)\n",
        "        #self.classes = self.classes.reshape((10, -1)) # each row contains the classes for the corrisponding batch\n",
        "        #print(self.classes)\n",
        "        self.__dictionary = {}\n",
        "        for i, c in enumerate(self.classes):\n",
        "          self.__dictionary[c] = i\n",
        "\n",
        "\n",
        "    def get_dict(self):\n",
        "      return self.__dictionary\n",
        "    def __getitem__(self, index):\n",
        "        return index,self.dataset.__getitem__(index)[0],self.dataset.__getitem__(index)[1]\n",
        "    def __len__(self):\n",
        "        return self.dataset.__len__()\n",
        "    def getbatches(self):\n",
        "      classlist=self.classes\n",
        "      batches=[]\n",
        "      for i in range(0,int(100/self.classes_per_batch)):\n",
        "        #print(i)\n",
        "        batch=classlist[int(i*self.classes_per_batch):int(i*10+self.classes_per_batch)]\n",
        "        batches.append(batch)\n",
        "      return batches\n",
        "    def get_batch_indexes(self):\n",
        "      classlist=self.classes\n",
        "      numclass=self.classes_per_batch\n",
        "      batch_indexes=[]\n",
        "      for i in range(0,int(100/self.classes_per_batch)):\n",
        "        batch=classlist[int(i*numclass):int(i*numclass+numclass)]\n",
        "        mask=np.isin(self.targets,batch)\n",
        "        indexes=np.array(np.arange(len(self.dataset.targets)))\n",
        "        indexes=indexes[mask]\n",
        "        batch_indexes.append(indexes)\n",
        "      return batch_indexes\n",
        "    def get_class_indexes(self,label):\n",
        "      indexes = np.array(np.arange(len(self.dataset.targets)))\n",
        "      labels = self.dataset.targets\n",
        "      mask = np.isin(labels, label)\n",
        "      indexes = indexes[mask]\n",
        "\n",
        "      return indexes\n",
        "    def get_train_val(self,valid):\n",
        "      batches=self.get_batch_indexes()\n",
        "      train=[]\n",
        "      val=[]\n",
        "      for batch in batches:\n",
        "        #print(type(batch))\n",
        "        random.shuffle(batch)\n",
        "        valbatch=batch[0:int(valid*len(batch))]\n",
        "        trainbatch=batch[int(valid*len(batch)):]\n",
        "        train.append(trainbatch)\n",
        "        val.append(valbatch)\n",
        "      return train,val\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    mean = [0.5071, 0.4867, 0.4408]\n",
        "    std = [0.2675, 0.2565, 0.2761]\n",
        "    if not isinstance(input_image, np.ndarray):\n",
        "        if isinstance(input_image, torch.Tensor):\n",
        "            image_tensor = input_image.data\n",
        "        else:\n",
        "            return input_image\n",
        "        image_numpy = image_tensor.cpu().detach().float().numpy()\n",
        "        if image_numpy.shape[0] == 1:\n",
        "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "        for i in range(len(mean)): \n",
        "            image_numpy[i] = image_numpy[i] * std[i] + mean[i]\n",
        "        image_numpy = image_numpy * 255\n",
        "        image_numpy = np.transpose(image_numpy, (1, 2, 0))\n",
        "    else:\n",
        "        image_numpy = input_image\n",
        "    return image_numpy.astype(imtype)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4jUchQ1EAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5934e8d5-558d-4d3d-b07f-f5c6ef44ecbb"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "import copy\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from torch.utils.data import Subset, DataLoader, Dataset\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "import import_ipynb\n",
        "#from IncrementalLearning.cifar100 import ilCIFAR100\n",
        "\n",
        "from IncrementalLearning.resnet_cifar import resnet32\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /content/IncrementalLearning/resnet_cifar.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzqwQeHB1Tg-"
      },
      "source": [
        "class mnemonics():\n",
        "  def __init__(self, randomseed):\n",
        "    self.device = 'cuda'\n",
        "    self.model = resnet32(num_classes=100).to(self.device)\n",
        "    self.feature_extractor = self.model.features\n",
        "    self.temp_model = None\n",
        "    self.lr = 2\n",
        "    self.gamma = 0.2\n",
        "    self.weight_decay = 1e-5 \n",
        "    self.milestones = [49,63]\n",
        "    self.batch_size = 128\n",
        "    self.numepochs = 1\n",
        "    self.n_classes = 0\n",
        "    self.n_known = 0\n",
        "    self.feature_size=64\n",
        "    self.momentum=0.9\n",
        "    self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    self.NUM_BATCHES=10\n",
        "    self.randomseed=randomseed\n",
        "    self.trainloader=None\n",
        "    self.testloader=None\n",
        "    self.CLASSES_PER_BATCH=10\n",
        "\n",
        "    self.original_training_set = ilCIFAR100(self.CLASSES_PER_BATCH, self.randomseed, train = 'train')\n",
        "    self.original_exemplar_set = ilCIFAR100(self.CLASSES_PER_BATCH, self.randomseed, train = 'exemplars')\n",
        "    self.original_test_set = ilCIFAR100(self.CLASSES_PER_BATCH,self.randomseed, train= 'test')\n",
        "\n",
        "    self.last_test = None\n",
        "    self.y_pred = []\n",
        "    self.y_test = []\n",
        "\n",
        "    self.cumulative_class_mean = []\n",
        "\n",
        "    self.classes_seen=0\n",
        "    self.diz = self.original_training_set.get_dict()\n",
        "\n",
        "    self.exemplar_features_mean = None\n",
        "    # lista di liste, ogni lista contiene gli exemplars di una classe\n",
        "    self.exemplar_sets_idxs = [] # mn_exemplat_sets\n",
        "    # lista unica, tutti gli indici degli exemplar\n",
        "    self.exemplar_idxs = []\n",
        "\n",
        "\n",
        "  def update_params(self, \n",
        "                    m,\n",
        "                    finetuning_idxs, \n",
        "                    training_idxs, \n",
        "                    mnemonics_to_optimize, \n",
        "                    batch_size,\n",
        "                    new=True,\n",
        "                    lr=0.01, \n",
        "                    momentum=0.9, \n",
        "                    weight_decay=1e-5, \n",
        "                    milestones=[10, 20, 30, 40],\n",
        "                    gamma=0.5, \n",
        "                    tuning_epochs=2,\n",
        "                    updating_epochs=30):\n",
        "    \n",
        "    \"\"\"\n",
        "    finetuning_idxs = indexes of current task elements\n",
        "    mnemonics_idxs = indexes of exemplar elements\n",
        "    mnemonics_to_optimize = the optimized parameters in the update phase\n",
        "    \"\"\"\n",
        "\n",
        "    # make a copy of the model\n",
        "    model_copy = copy.deepcopy(self.model)\n",
        "    model_copy.train()\n",
        "    model_copy.to(self.device)\n",
        "\n",
        "    # define the loss\n",
        "    # criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # FINE TUNING FOR 1 EPOCH eq. 8 --------------------------------------------\n",
        "    \n",
        "    # define optimizer and scheduler for fine tuning phase\n",
        "    optimizer = optim.SGD(model_copy.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    \n",
        "    # create the subset dataset to load the data you want, and the loader\n",
        "    finetuning_labels = np.array([self.original_training_set.__getitem__(idx)[2] for idx in finetuning_idxs], dtype=int)\n",
        "    meta_idxs = [i for i in range(len(finetuning_idxs))]\n",
        "    random.shuffle(meta_idxs)\n",
        "\n",
        "    # split the meta idxs in batches\n",
        "    n_batches = int(np.floor(len(finetuning_idxs)/batch_size))\n",
        "    meta_idxs_batches = []\n",
        "    for i in range(n_batches):\n",
        "      meta_idxs_batches.append(np.array(meta_idxs[batch_size*i:batch_size*(i+1)]))\n",
        "    meta_idxs_batches.append(np.array(meta_idxs[batch_size*n_batches:]))\n",
        "\n",
        "    # now fine tune the copied model\n",
        "    for epoch in range(tuning_epochs):\n",
        "      for meta_idxs_batch in meta_idxs_batches:\n",
        "        inputs = mnemonics_to_optimize[0][meta_idxs_batch] # are already in cuda\n",
        "        labels = finetuning_labels[meta_idxs_batch]\n",
        "        labels = torch.tensor([self.diz[c] for c in labels])\n",
        "        labels = labels.to(self.device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_copy(inputs)\n",
        "        labels_encoded = F.one_hot(labels,100).float().to(self.device)\n",
        "        loss = self.criterion(outputs, labels_encoded)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "\n",
        "    # UPDATE THE MNEMONICS eq.9/10 ---------------------------------------------\n",
        "    \n",
        "    model_copy.eval()\n",
        "    \n",
        "    optimizer = optim.SGD(mnemonics_to_optimize, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "    \n",
        "\n",
        "    if new:\n",
        "      exlvl_training = Subset(self.original_training_set, training_idxs)\n",
        "      exlvl_loader = DataLoader(exlvl_training, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "      current_task_labels = set([self.original_training_set.__getitem__(idx)[2] for idx in training_idxs])\n",
        "      new_dict = {label:new_label for label, new_label in zip(current_task_labels, range(10))}\n",
        "\n",
        "      new_class_mean = {new_dict[key] : value for key, value in self.cumulative_class_mean.items()}\n",
        "      #print('newdict', new_dict)\n",
        "      #print('cumulative', self.cumulative_class_mean)\n",
        "      #print('new class mean', new_class_mean)\n",
        "      #print('sorted', sorted(new_class_mean.items()))\n",
        "      means_ready = torch.Tensor(list(new_class_mean.values()))\n",
        "\n",
        "    \n",
        "    else:\n",
        "      exlvl_training = Subset(self.original_exemplar_set, training_idxs)\n",
        "      exlvl_loader = DataLoader(exlvl_training, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "    for epoch in tqdm(range(updating_epochs)):\n",
        "      for _, inputs, labels in exlvl_loader:\n",
        "\n",
        "        if new:\n",
        "          labels = torch.tensor([new_dict[c.item()] for c in labels])\n",
        "        else:\n",
        "          labels = torch.tensor([self.diz[c.item()] for c in labels])\n",
        "\n",
        "        labels = labels.to(self.device)\n",
        "        inputs = inputs.to(self.device)\n",
        "        out_features = model_copy.features(inputs)\n",
        "        # compute features mean of mnemonics for each class\n",
        "        all_class_means = torch.zeros((0, 64))\n",
        "        all_class_means = all_class_means.to(self.device)\n",
        "        n_classes = int(len(finetuning_labels)/m)\n",
        "        if new:\n",
        "          the_logits = F.linear(F.normalize(out_features, p=2, dim=1), F.normalize(means_ready, p=2, dim=1))\n",
        "        else:\n",
        "          for i in range(n_classes): # how many classes\n",
        "            mnemonics_features = model_copy.features(mnemonics_to_optimize[0][i*m:(i+1)*m])\n",
        "            this_class_means = torch.mean(mnemonics_features, dim=0) # size 64\n",
        "            this_class_means = torch.unsqueeze(this_class_means, dim=0) # add the second dimension\n",
        "            all_class_means = torch.cat((all_class_means, this_class_means), dim=0)\n",
        "          the_logits = F.linear(F.normalize(out_features, p=2, dim=1), F.normalize(all_class_means, p=2, dim=1))\n",
        "        labels_encoded = F.one_hot(labels,100).float().cuda()\n",
        "        loss = F.cross_entropy(the_logits, labels) # al secondo batch di classi per i new mnemonics le uscite sono sempre 10 ma le label vanno da 10 a 19\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "  def exemplar_level_optimization(self, m, task_num, current_task_indices):  \n",
        "    \n",
        "    # UPDATING NEW EXEMPLAR-----------------------------------------------------\n",
        "\n",
        "    # isola gli indici dei nuovi exemplars\n",
        "    new_exemplar_idxs = []\n",
        "    for idxs in self.exemplar_sets_idxs[-10:]:\n",
        "      new_exemplar_idxs += idxs\n",
        "\n",
        "    # ora ottieni gli mnemonics che poi sono da ottimizzare\n",
        "    new_mnemonics_data = torch.zeros((10*m, 3, 32, 32))\n",
        "\n",
        "    for i, idx in enumerate(new_exemplar_idxs):\n",
        "      new_mnemonics_data[i, :, :, :] = self.original_training_set.__getitem__(int(idx))[1]\n",
        "\n",
        "    new_mnemonics = nn.ParameterList()\n",
        "    new_mnemonics.append(nn.Parameter(new_mnemonics_data))\n",
        "    new_mnemonics.to(self.device)\n",
        "    \n",
        "    #print(new_mnemonics[0][0])\n",
        "\n",
        "    options_new ={'finetuning_idxs': new_exemplar_idxs, \n",
        "                  'training_idxs': current_task_indices, \n",
        "                  'mnemonics_to_optimize':  new_mnemonics,  \n",
        "                  'batch_size':128,\n",
        "                  'm':m}\n",
        "\n",
        "    print('---start mnemonics updating---')\n",
        "\n",
        "    self.update_params(**options_new)    \n",
        "\n",
        "    for i, idx in enumerate(new_exemplar_idxs):\n",
        "      self.original_training_set.dataset.data[idx] = tensor2im(new_mnemonics[0][i])\n",
        "\n",
        "    \n",
        "    # UPDATING OLD EXEMPLARS ---------------------------------------------------\n",
        "    '''\n",
        "    if task_num:\n",
        "      # decidi quanti elementi ha ogni exemlar set in a e in b a seconda se m è \n",
        "      # pari o dispari\n",
        "      if m%2:\n",
        "        l_a = int((m+1)/2)\n",
        "      else:\n",
        "        l_a = int(m/2)\n",
        "      l_b = int(m-l_a)\n",
        "\n",
        "      # isola gli indici dei vecchi exemplars, dividendoli in due parti\n",
        "      # ogni classe deve avere circa la metà degli exemplar originali\n",
        "      old_exemplar_idxs_a = []\n",
        "      old_exemplar_idxs_b = []\n",
        "      \n",
        "      for idxs in self.exemplar_sets_idxs[:-10]:\n",
        "        old_exemplar_idxs_a += idxs[:l_a]\n",
        "        old_exemplar_idxs_b += idxs[l_a:]\n",
        "\n",
        "      old_mnemonics_data_a = torch.zeros((task_num*10*l_a, 3, 32, 32))\n",
        "      old_mnemonics_data_b = torch.zeros((task_num*10*l_b, 3, 32, 32))\n",
        "\n",
        "      for i, idx in enumerate(old_exemplar_idxs_a):\n",
        "        old_mnemonics_data_a[i, :, :, :] = self.original_training_set.__getitem__(int(idx))[1]\n",
        "      \n",
        "      for i, idx in enumerate(old_exemplar_idxs_b):\n",
        "          old_mnemonics_data_b[i, :, :, :] = self.original_training_set.__getitem__(int(idx))[1]\n",
        "      \n",
        "      old_mnemonics_a = nn.ParameterList()\n",
        "      old_mnemonics_a.append(nn.Parameter(old_mnemonics_data_a))\n",
        "      old_mnemonics_a.to(self.device)\n",
        "      old_mnemonics_b = nn.ParameterList()\n",
        "      old_mnemonics_b.append(nn.Parameter(old_mnemonics_data_b))\n",
        "      old_mnemonics_b.to(self.device)\n",
        "\n",
        "      options_old_a = {'finetuning_idxs':old_exemplar_idxs_a, \n",
        "                       'training_idxs':old_exemplar_idxs_b, \n",
        "                       'mnemonics_to_optimize':old_mnemonics_a, \n",
        "                       'batch_size':128,\n",
        "                       'm': l_a,\n",
        "                       'new':False}\n",
        "\n",
        "      options_old_b = {'finetuning_idxs':old_exemplar_idxs_b, \n",
        "                       'training_idxs':old_exemplar_idxs_a, \n",
        "                       'mnemonics_to_optimize':old_mnemonics_b, \n",
        "                       'batch_size':128,\n",
        "                       'm':l_b,\n",
        "                       'new':False}\n",
        "\n",
        "      self.update_params(**options_old_a) \n",
        "      self.update_params(**options_old_b)\n",
        "\n",
        "      # CONVERT AND STORE UPDATED EXEMPLAR as numpy array\n",
        "\n",
        "      for i, idx in enumerate(old_exemplar_idxs_a):\n",
        "        self.original_training_set.dataset.data[idx] = tensor2im(old_mnemonics_a[0][i])\n",
        "\n",
        "      for i, idx in enumerate(old_exemplar_idxs_b):\n",
        "        self.original_training_set.dataset.data[idx] = tensor2im(old_mnemonics_b[0][i])\n",
        "    \n",
        "    '''\n",
        "\n",
        "    # FINE TUNE THE CURRENT NET ON ALL THE EXEMPLARS COLLECTED 'TILL NOW\n",
        "    \n",
        "\n",
        "  def model_level_optimization(self):\n",
        "    \n",
        "    old_model = copy.deepcopy(self.model)\n",
        "    old_model.eval()\n",
        "    old_model.to(self.device)\n",
        "    n_classes = self.classes_seen+self.CLASSES_PER_BATCH\n",
        "    print(n_classes)\n",
        "    optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.milestones, gamma=self.gamma)\n",
        "    for epoch in tqdm(range(self.numepochs)):\n",
        "        \n",
        "      for _, inputs, labels in self.trainloader:\n",
        "        inputs = inputs.float().to(self.device)\n",
        "        labels = torch.tensor([self.diz[c.item()] for c in labels])\n",
        "\n",
        "        labels=labels.to(self.device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs=self.model(inputs)\n",
        "\n",
        "        labels_encoded = F.one_hot(labels,100).float().to(self.device) #CAMBIARE ONE_HOT\n",
        "        \n",
        "        if self.classes_seen:\n",
        "          old_target = old_model(inputs).to(self.device)\n",
        "          old_target = torch.sigmoid(old_target).to(self.device)\n",
        "          \n",
        "          target = torch.cat((old_target[:,:self.classes_seen], labels_encoded[:, self.classes_seen:]), dim=1)\n",
        "          loss = self.criterion(outputs, target)\n",
        "        else:\n",
        "          loss = self.criterion(outputs, labels_encoded) \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "      scheduler.step()\n",
        "\n",
        "\n",
        "  def classify_nme(self, input_batch):\n",
        "    min_distances = float('inf')*torch.ones(len(input_batch)).to(self.device) # shape: batch_size --> 128\n",
        "    y_pred = torch.zeros(len(input_batch), dtype=torch.int8).to(self.device) # shape: batch_size --> 128\n",
        "    input_features = self.model.features(input_batch) # shape: (batch_size, feature_size) --> (128, 64)\n",
        "\n",
        "    for i in range(len(self.exemplar_sets_idxs)):\n",
        "      ex_mean = self.exemplar_means[i,:]\n",
        "\n",
        "      # compute distances between inputs features and exemplar set means\n",
        "      pdist = nn.PairwiseDistance(p=2)\n",
        "      distances = pdist(input_features, ex_mean) # shape: batch_size --> 128\n",
        "\n",
        "      # update min distancies and predicted labels\n",
        "      mask = distances < min_distances\n",
        "      min_distances[mask] = distances[mask]\n",
        "      y_pred[mask] = self.exemplar_labels[i]\n",
        "\n",
        "    return y_pred\n",
        "    \n",
        "\n",
        "  def get_new_exemplars(self, batch_indexes, m):\n",
        "    self.exemplar_sets_idxs.append(random.sample(list(batch_indexes), m))\n",
        "\n",
        "\n",
        "  def reduce_old_exemplars(self, m):\n",
        "    for i, set_i in enumerate(self.exemplar_sets_idxs):\n",
        "      self.exemplar_sets_idxs[i] = random.sample(set_i, m)\n",
        "\n",
        "  def __accuracy_fc(self, dl, mapper):\n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    for  _, images, labels in dl:\n",
        "      labels = torch.tensor([torch.tensor(mapper[c.item()]) for c in labels])\n",
        "      labels = labels.to(self.device)\n",
        "      images = images.to(self.device)\n",
        "      outputs = self.model(images)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      total += len(labels)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "\n",
        "    acc = correct / total\n",
        "    return acc\n",
        "\n",
        "\n",
        "  def __accuracy_nme(self, dl):\n",
        "    \n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    \n",
        "    for  _, images, labels in dl:\n",
        "      labels = labels.to(self.device)\n",
        "      images = images.to(self.device)\n",
        "      preds = self.classify_nme(images)\n",
        "      total += len(labels)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "\n",
        "      if self.last_test:\n",
        "        self.y_pred += preds.tolist()\n",
        "        self.y_test += labels.tolist()\n",
        "\n",
        "    acc = correct / total\n",
        "    return acc\n",
        "\n",
        "\n",
        "  def plot_confusion_matrix(self):\n",
        " \n",
        "    cm = confusion_matrix(self.y_test, self.y_pred)\n",
        "    cm = np.log(cm+1)\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    sns.heatmap(cm, square=True, cbar=False, ax=ax, cmap=plt.get_cmap('seismic'))\n",
        "    ax.set_xticks(np.linspace(19,99,5))\n",
        "    ax.set_yticks(np.linspace(19,99,5))\n",
        "    ax.set_xticklabels([20,40,60,80,100], rotation=0)\n",
        "    ax.set_yticklabels([20,40,60,80,100], rotation=0)\n",
        "    ax.set_title(\"iCaRL\")\n",
        "    ax.set_xlabel(\"Predicted class\")\n",
        "    ax.set_ylabel(\"True class\")\n",
        "    plt.savefig(\"iCaRL_\"+str(self.randomseed)+\"_cm.png\")\n",
        "    plt.show()\n",
        "    return cm\n",
        "\n",
        "  def plot_data(self, dl):\n",
        "\n",
        "    from sklearn.manifold import TSNE\n",
        "\n",
        "    labels_array = torch.zeros(0).to('cuda')\n",
        "    dataset_to_reduce = torch.zeros((0, 64)).to('cuda')\n",
        "\n",
        "    for  _, images, labels in dl:\n",
        "      labels = labels.to(self.device)\n",
        "      images = images.to(self.device)\n",
        "      dataset_to_reduce = torch.cat((dataset_to_reduce, self.feature_extractor(images)))\n",
        "      labels_array = torch.cat((labels_array, labels))\n",
        "\n",
        "\n",
        "    print('example:', dataset_to_reduce[0])\n",
        "    print('len of dataset to reduce:', dataset_to_reduce[0].shape)\n",
        "    print('example:', dataset_to_reduce[0][0])\n",
        "    X_transformed = TSNE(n_components=2).fit_transform(dataset_to_reduce.cpu())\n",
        "    \n",
        "    print('shape of transofmed', X_transormed.shape)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(15,15))\n",
        "    ax.scatter(X_transformed[:,0], X_transormed[:,1], c = labels_array)\n",
        "    plt.show()\n",
        "\n",
        "   # for idx in data_idxs:\n",
        "    #  dataset_to_reduce.append([dataset.__getitem__(idx)[1], dataset.__getitem__(idx)[2]])\n",
        "    \n",
        "  def trainer(self):\n",
        "    \n",
        "    train_indices = self.original_training_set.get_batch_indexes()\n",
        "    test_indices = self.original_test_set.get_batch_indexes()\n",
        "    batches=self.original_training_set.getbatches()\n",
        "    current_test_indexes=[]\n",
        "    test_acc = []\n",
        "    self.last_test = False\n",
        "\n",
        "    for i in range(self.NUM_BATCHES):\n",
        "\n",
        "      if i == self.NUM_BATCHES-1:\n",
        "        self.last_test = True\n",
        "\n",
        "      current_exemplar_indices = np.array([], dtype=int)\n",
        "\n",
        "      for exemplar_set in self.exemplar_sets_idxs:\n",
        "        current_exemplar_indices = np.concatenate([current_exemplar_indices, np.array(exemplar_set)])\n",
        "\n",
        "      exemplar_dataset = Subset(self.original_exemplar_set, current_exemplar_indices)\n",
        "\n",
        "      train_dataset = Subset(self.original_training_set, train_indices[i])\n",
        "      current_test_indexes += test_indices[i].tolist()\n",
        "      test_dataset = Subset(self.original_test_set,current_test_indexes)\n",
        "      self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "      self.testloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4, drop_last=True)        \n",
        "      \n",
        "\n",
        "      if i == 0:\n",
        "        self.trainloader = self.train_loader\n",
        "      else:\n",
        "        self.trainloader = DataLoader(torch.utils.data.ConcatDataset([train_dataset, exemplar_dataset]), batch_size=self.batch_size, shuffle=True,\n",
        "          num_workers=4, pin_memory=True)\n",
        "        \n",
        "        print('lunghezza train loader:', len(self.trainloader))\n",
        "        \n",
        "      self.model.train()\n",
        "      self.model_level_optimization()    \n",
        "      self.classes_seen += 10\n",
        "      self.model.eval() # Set Network to evaluation mode\n",
        "\n",
        "      #self.plot_data(self.trainloader)\n",
        "\n",
        "      # update exemplars number\n",
        "      m=int(2000/(int(i*10+10)))\n",
        "\n",
        "      # reduce the number of each exemplars set\n",
        "      self.reduce_old_exemplars(m) \n",
        "      \n",
        "      self.cumulative_class_mean = {}\n",
        "\n",
        "      for classlabel in batches[i]:\n",
        "        indexes_class = self.original_training_set.get_class_indexes(classlabel)\n",
        "        #current_class = Subset(self.original_training_set, indexes_class)\n",
        "        self.get_new_exemplars(indexes_class, m)\n",
        "        indexes_class = self.original_training_set.get_class_indexes(classlabel)\n",
        "        current_class = Subset(self.original_training_set, indexes_class)\n",
        "\n",
        "        loader = torch.utils.data.DataLoader(current_class, batch_size=self.batch_size,shuffle=False, num_workers=4)\n",
        "        features = np.zeros((0, 64))\n",
        "        with torch.no_grad():\n",
        "          for indexes, images, labels in loader:\n",
        "            images = images.cuda()\n",
        "            feature = self.feature_extractor(images).data.cpu().numpy()\n",
        "            feature = normalize(feature, axis=1, norm='l2')\n",
        "            features = np.concatenate((features,feature), axis=0)\n",
        "\n",
        "        class_mean = np.mean(features, axis=0)\n",
        "        class_mean = class_mean / np.linalg.norm(class_mean)  # Normalize\n",
        "\n",
        "        self.cumulative_class_mean[classlabel] = class_mean\n",
        "        \n",
        "\n",
        "      \n",
        "      if i != 9:\n",
        "        self.exemplar_level_optimization(m, i, self.original_training_set.get_batch_indexes()[i])\n",
        "\n",
        "      # compute means of exemplar set\n",
        "      # cycle for each exemplar set\n",
        "      self.exemplar_means = torch.zeros((0, self.feature_size), dtype=torch.float).to(self.device)\n",
        "      self.exemplar_labels = []\n",
        "      for i in range(len(self.exemplar_sets_idxs)):\n",
        "        exemplars_dataset = Subset(self.original_training_set, self.exemplar_sets_idxs[i])\n",
        "        exemplars_loader = torch.utils.data.DataLoader(exemplars_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
        "        ex_features = torch.zeros((0, self.feature_size), dtype=torch.float).to(self.device) # alla fine shape: (len(exemplar_set), feature_size) --> (m, 64)\n",
        "      \n",
        "        with torch.no_grad():\n",
        "          _, _, exemplar_label = self.original_training_set.__getitem__(self.exemplar_sets_idxs[i][0]) \n",
        "          self.exemplar_labels.append(exemplar_label)\n",
        "          # cycle for each batch in the current exemplar set\n",
        "          for _,  exemplars, _ in exemplars_loader:\n",
        "          \n",
        "            # get exemplars features\n",
        "            exemplars = exemplars.to(self.device)\n",
        "            features = self.model.features(exemplars) # shape: (len(exemplars), feature_size)\n",
        "          \n",
        "            # normalize \n",
        "            feature_norms = torch.norm(features, p=2, dim=1) # shape: len(exemplars)\n",
        "            feature_norms.unsqueeze_(1) # shape: (len(exemplars), 1)\n",
        "            features = features/feature_norms\n",
        "          \n",
        "            # concatenate over columns\n",
        "            ex_features = torch.cat((ex_features, features), dim=0)\n",
        "          \n",
        "        # compute current exemplar set mean and normalize it\n",
        "        ex_mean = torch.mean(ex_features, dim=0) # shape: feature_size --> 64\n",
        "        ex_mean = ex_mean/torch.norm(ex_mean)\n",
        "        ex_mean.unsqueeze_(0) # shape: (1, feature_size) --> (1, 64)\n",
        "        self.exemplar_means = torch.cat((self.exemplar_means, ex_mean), dim=0) # shape: (n_examplar sets, feature size)\n",
        "      \n",
        "\n",
        "      print('accuracy on training set:', 100*self.__accuracy_fc(self.trainloader,self.diz))\n",
        "      # print('accuracy on test set:', self.__accuracy_on(self.testloader,self,self.diz))\n",
        "      current_test_acc = self.__accuracy_nme(self.testloader)\n",
        "      print('accuracy on test set:', 100*current_test_acc)\n",
        "      print('-' * 80)\n",
        "      test_acc.append(current_test_acc)\n",
        "\n",
        "    # compute comfusion matrix and save results\n",
        "    cm = self.plot_confusion_matrix()\n",
        "    with open('iCaRL_'+str(self.randomseed)+\"_cm\", 'wb') as file:\n",
        "      pickle.dump(cm, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open('iCaRL_'+str(self.randomseed)+\"_testacc\", 'wb') as file:\n",
        "      pickle.dump(test_acc, file, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "259c7293bcf149739326b5920e351742",
            "8ef89a0753bb4e539c609d79c31207bd",
            "e2cc74e49a75495c80b2ae28a65ea889",
            "b4a7fe27aca84913ab171db5a589737f",
            "6925bddeeeeb4012b2f07f81900fd9ad",
            "86665b3332cb47c0b49eadc4a412485c",
            "878f69bcc6ed4094acd811bf2f60d052",
            "04c44032756b4f2cacd33959bcc3c554",
            "00e27416b0e5401f9ae04d528cdf3242",
            "99ebb9bed54442b0bb5a9c47b759fd34",
            "674dab1540724fc895a3eac3e9d132b2",
            "cf7435b0a4c94f80afe2d726c52c9604",
            "5260d34bf31740a899b508343e17429f",
            "ea33477caf6042998a2b1c77410e06e6",
            "878f6240835744ca92eeaf5f6664805b",
            "955bef1d2d0a44b186aa0497a5ed417c"
          ]
        },
        "id": "OYzLuYGDLr15",
        "outputId": "111ebfc0-2816-4ddd-fa55-3475dd9e9641"
      },
      "source": [
        "method = mnemonics(randomseed=203)\n",
        "method.trainer()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "259c7293bcf149739326b5920e351742",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "---start mnemonics updating---\n",
            "newdict {96: 0, 33: 1, 3: 2, 5: 3, 11: 4, 76: 5, 78: 6, 62: 7, 27: 8, 30: 9}\n",
            "cumulative {11: array([0.11478377, 0.09573872, 0.11334106, 0.07356598, 0.10375725,\n",
            "       0.07664447, 0.21082932, 0.08269825, 0.03474149, 0.12407912,\n",
            "       0.07467396, 0.14944355, 0.07321193, 0.26733924, 0.07716078,\n",
            "       0.10625511, 0.1193089 , 0.07339835, 0.04522939, 0.15713954,\n",
            "       0.16908594, 0.09109797, 0.1118566 , 0.04654253, 0.07798271,\n",
            "       0.12124483, 0.10925392, 0.18708963, 0.13651516, 0.07134686,\n",
            "       0.25613617, 0.12832826, 0.09289955, 0.01988344, 0.23898355,\n",
            "       0.06482295, 0.04691762, 0.12228998, 0.0579396 , 0.0986282 ,\n",
            "       0.04682863, 0.18872884, 0.0637376 , 0.17143292, 0.17728179,\n",
            "       0.10867876, 0.22670674, 0.10237628, 0.06233365, 0.20415271,\n",
            "       0.1183183 , 0.13471816, 0.05216757, 0.06655449, 0.1713834 ,\n",
            "       0.07274779, 0.08313703, 0.13598381, 0.07042525, 0.05905767,\n",
            "       0.14290069, 0.11442528, 0.10125687, 0.08562214]), 5: array([0.13781628, 0.10606699, 0.09952901, 0.08678932, 0.09840753,\n",
            "       0.09717839, 0.15530414, 0.11610417, 0.04972309, 0.09636052,\n",
            "       0.09590003, 0.19937423, 0.09250805, 0.19991372, 0.1151357 ,\n",
            "       0.15279621, 0.11309836, 0.08468289, 0.06433315, 0.1396823 ,\n",
            "       0.14915374, 0.12096542, 0.11267195, 0.07699537, 0.08301379,\n",
            "       0.147841  , 0.12353611, 0.17947379, 0.15701896, 0.0946412 ,\n",
            "       0.20268526, 0.13518538, 0.09366258, 0.03721895, 0.20414191,\n",
            "       0.08409028, 0.05670177, 0.12926805, 0.07503   , 0.09320334,\n",
            "       0.04904286, 0.15991373, 0.08280655, 0.13649868, 0.18216036,\n",
            "       0.13155547, 0.18612843, 0.08294634, 0.08295596, 0.21259428,\n",
            "       0.14847013, 0.14945545, 0.0640844 , 0.08106896, 0.14592071,\n",
            "       0.09932708, 0.13684949, 0.11127421, 0.08854388, 0.07310241,\n",
            "       0.11445795, 0.15696401, 0.11709789, 0.09376653]), 62: array([0.05023949, 0.03419987, 0.12442881, 0.05840653, 0.10818843,\n",
            "       0.01630244, 0.25728563, 0.01573   , 0.00860237, 0.17910544,\n",
            "       0.04881922, 0.07693389, 0.02924363, 0.37606751, 0.04028455,\n",
            "       0.05353524, 0.09389309, 0.02117549, 0.0218323 , 0.15968001,\n",
            "       0.16196064, 0.03001266, 0.04927124, 0.03526409, 0.04171073,\n",
            "       0.04065762, 0.05948471, 0.20562807, 0.04319872, 0.04002913,\n",
            "       0.33743645, 0.0859173 , 0.08004192, 0.00557826, 0.3391862 ,\n",
            "       0.0149733 , 0.01385645, 0.05897964, 0.01336121, 0.07129734,\n",
            "       0.02924857, 0.21791755, 0.02372117, 0.21360299, 0.09984355,\n",
            "       0.11204379, 0.30103434, 0.12154815, 0.02101734, 0.12431641,\n",
            "       0.0267015 , 0.0723602 , 0.0167318 , 0.01480794, 0.22115984,\n",
            "       0.01951508, 0.02938783, 0.10162091, 0.03315429, 0.02372785,\n",
            "       0.17743947, 0.03410064, 0.02835786, 0.02773892]), 76: array([0.11726705, 0.18755229, 0.18638842, 0.0303511 , 0.03100559,\n",
            "       0.2022525 , 0.18957512, 0.1441359 , 0.09792718, 0.07282085,\n",
            "       0.02598089, 0.07619211, 0.15280255, 0.14134678, 0.05167218,\n",
            "       0.1327255 , 0.04840603, 0.11817806, 0.06176575, 0.10740092,\n",
            "       0.07864773, 0.12150679, 0.13010246, 0.07154852, 0.05871599,\n",
            "       0.1419627 , 0.07849611, 0.08135735, 0.13801387, 0.07558669,\n",
            "       0.05096913, 0.04733445, 0.02183325, 0.03578872, 0.03262279,\n",
            "       0.12287921, 0.12266299, 0.20143601, 0.10207446, 0.07409028,\n",
            "       0.09019391, 0.04528398, 0.05775919, 0.08022931, 0.16314806,\n",
            "       0.10304727, 0.05138952, 0.11128049, 0.21471605, 0.15607867,\n",
            "       0.16692078, 0.20916095, 0.16108104, 0.13383452, 0.20547128,\n",
            "       0.08222299, 0.04170028, 0.07240833, 0.03870296, 0.06906039,\n",
            "       0.10122058, 0.12698627, 0.37939838, 0.1051702 ]), 27: array([0.11593466, 0.10186033, 0.16149091, 0.10963202, 0.07766145,\n",
            "       0.07429084, 0.13601918, 0.11306022, 0.06999059, 0.14058722,\n",
            "       0.11447763, 0.13558903, 0.12737197, 0.16144686, 0.11402956,\n",
            "       0.11854429, 0.17013647, 0.09521648, 0.13337699, 0.11101506,\n",
            "       0.10515794, 0.11772509, 0.12566152, 0.08801884, 0.11360252,\n",
            "       0.15346807, 0.17442016, 0.18939709, 0.15341654, 0.09481457,\n",
            "       0.14805666, 0.12633891, 0.08157283, 0.06517872, 0.14430755,\n",
            "       0.09218882, 0.08131149, 0.12450248, 0.11885082, 0.09646019,\n",
            "       0.10656106, 0.13964167, 0.10651291, 0.11942925, 0.15509423,\n",
            "       0.09057445, 0.14794798, 0.11456901, 0.13093598, 0.17516609,\n",
            "       0.14184825, 0.12102373, 0.09372968, 0.10245907, 0.08110255,\n",
            "       0.13931958, 0.15402826, 0.09586393, 0.11249112, 0.13501919,\n",
            "       0.12694934, 0.14444545, 0.16628695, 0.1192072 ]), 3: array([0.12526161, 0.11443611, 0.15039311, 0.09356607, 0.08317217,\n",
            "       0.08859479, 0.14696862, 0.12016658, 0.06298356, 0.12799131,\n",
            "       0.0888384 , 0.12459345, 0.12432993, 0.18120118, 0.08958166,\n",
            "       0.11733606, 0.14947819, 0.10562994, 0.10263936, 0.12702841,\n",
            "       0.11738952, 0.11959571, 0.13629402, 0.06410093, 0.10864255,\n",
            "       0.165044  , 0.15479105, 0.16970294, 0.1669162 , 0.09057553,\n",
            "       0.15647122, 0.13003751, 0.08474161, 0.04676836, 0.14224928,\n",
            "       0.09764499, 0.08232632, 0.14319778, 0.12037173, 0.10143942,\n",
            "       0.08847374, 0.14442383, 0.1021217 , 0.12459873, 0.18056211,\n",
            "       0.08325914, 0.14909976, 0.11527086, 0.12493023, 0.19053712,\n",
            "       0.15150176, 0.14184821, 0.09008636, 0.10678702, 0.09552373,\n",
            "       0.12865109, 0.11863239, 0.10883348, 0.09841367, 0.12366397,\n",
            "       0.13302357, 0.13494914, 0.1741777 , 0.12950221]), 96: array([0.09218672, 0.09153191, 0.2604479 , 0.1061918 , 0.04680765,\n",
            "       0.05486973, 0.15916818, 0.08551205, 0.08799052, 0.19600943,\n",
            "       0.09047261, 0.05319216, 0.16043566, 0.13889081, 0.08135959,\n",
            "       0.10306617, 0.20949729, 0.08739343, 0.1783856 , 0.09668482,\n",
            "       0.05873017, 0.14951651, 0.10576827, 0.07071922, 0.10383934,\n",
            "       0.16285453, 0.20390852, 0.18073495, 0.15161361, 0.07930991,\n",
            "       0.11187391, 0.09937937, 0.05025693, 0.08125488, 0.08959228,\n",
            "       0.06817491, 0.09002481, 0.10641179, 0.1267611 , 0.07378706,\n",
            "       0.19121772, 0.10296389, 0.09534736, 0.10295642, 0.1128604 ,\n",
            "       0.04642194, 0.10819896, 0.15195943, 0.17030894, 0.15224551,\n",
            "       0.11716902, 0.11585153, 0.09799701, 0.11506182, 0.05689884,\n",
            "       0.12301023, 0.0843181 , 0.10207433, 0.09538218, 0.18143874,\n",
            "       0.13924175, 0.10067818, 0.21579066, 0.11548632]), 33: array([0.08785102, 0.08709307, 0.22369722, 0.11750636, 0.06403991,\n",
            "       0.04775362, 0.15759068, 0.08101899, 0.07254163, 0.18812185,\n",
            "       0.10270039, 0.07140358, 0.13442617, 0.15900815, 0.09142791,\n",
            "       0.09330967, 0.21607828, 0.08800635, 0.1622414 , 0.11096152,\n",
            "       0.07950162, 0.12968392, 0.11715004, 0.0712447 , 0.11896369,\n",
            "       0.14903233, 0.20456754, 0.19350082, 0.1519084 , 0.07742746,\n",
            "       0.14317092, 0.12014983, 0.06978162, 0.07272503, 0.13027953,\n",
            "       0.0679674 , 0.08297978, 0.10449544, 0.12416439, 0.08811866,\n",
            "       0.1634947 , 0.134699  , 0.10330083, 0.11561041, 0.12382646,\n",
            "       0.0539063 , 0.14250438, 0.14470048, 0.14244654, 0.1580019 ,\n",
            "       0.11929562, 0.10268056, 0.09169696, 0.10003667, 0.06129665,\n",
            "       0.13251223, 0.1033246 , 0.10649753, 0.10719924, 0.17543331,\n",
            "       0.14115263, 0.10746643, 0.1755924 , 0.11914777]), 78: array([0.1189019 , 0.09060732, 0.10759823, 0.10741123, 0.09983272,\n",
            "       0.0669814 , 0.13970453, 0.09641685, 0.04791318, 0.11460173,\n",
            "       0.1228805 , 0.19031063, 0.08888945, 0.18917529, 0.13189442,\n",
            "       0.1303978 , 0.14776785, 0.08466941, 0.09072529, 0.13205802,\n",
            "       0.14202512, 0.10304028, 0.11312896, 0.09184902, 0.1021631 ,\n",
            "       0.13973667, 0.14569992, 0.19879477, 0.14453598, 0.08985448,\n",
            "       0.20170619, 0.14876019, 0.09958177, 0.04544533, 0.2142742 ,\n",
            "       0.07878458, 0.05791086, 0.11127169, 0.08437684, 0.09549391,\n",
            "       0.06179232, 0.17216453, 0.09439202, 0.13715939, 0.16830992,\n",
            "       0.11877957, 0.19538521, 0.08985427, 0.08241156, 0.19612838,\n",
            "       0.13390542, 0.11751563, 0.06172326, 0.07835838, 0.10490902,\n",
            "       0.11669079, 0.16905949, 0.10481976, 0.10978294, 0.09684131,\n",
            "       0.11639624, 0.15860398, 0.10165056, 0.09848056]), 30: array([0.0833029 , 0.2016716 , 0.19410485, 0.01299113, 0.01693181,\n",
            "       0.21841496, 0.24898809, 0.11320683, 0.10196758, 0.05205431,\n",
            "       0.0111944 , 0.06898958, 0.12052266, 0.14497694, 0.03756836,\n",
            "       0.10198067, 0.02947437, 0.11225155, 0.04466856, 0.10531308,\n",
            "       0.08075935, 0.07513083, 0.12801112, 0.07652609, 0.03979425,\n",
            "       0.09802156, 0.05292415, 0.0699843 , 0.09843712, 0.05069944,\n",
            "       0.0385793 , 0.02327597, 0.00855896, 0.02633337, 0.01179064,\n",
            "       0.1203493 , 0.12432715, 0.21082539, 0.06399556, 0.0655534 ,\n",
            "       0.08298394, 0.02555956, 0.03762431, 0.08944481, 0.13562811,\n",
            "       0.11389569, 0.03716494, 0.10885066, 0.22187478, 0.14182296,\n",
            "       0.15044818, 0.18136748, 0.17990081, 0.13540515, 0.25480897,\n",
            "       0.04867151, 0.02344846, 0.07598444, 0.02148904, 0.03889058,\n",
            "       0.08342418, 0.11896746, 0.4580463 , 0.07017718])}\n",
            "new class mean {4: array([0.11478377, 0.09573872, 0.11334106, 0.07356598, 0.10375725,\n",
            "       0.07664447, 0.21082932, 0.08269825, 0.03474149, 0.12407912,\n",
            "       0.07467396, 0.14944355, 0.07321193, 0.26733924, 0.07716078,\n",
            "       0.10625511, 0.1193089 , 0.07339835, 0.04522939, 0.15713954,\n",
            "       0.16908594, 0.09109797, 0.1118566 , 0.04654253, 0.07798271,\n",
            "       0.12124483, 0.10925392, 0.18708963, 0.13651516, 0.07134686,\n",
            "       0.25613617, 0.12832826, 0.09289955, 0.01988344, 0.23898355,\n",
            "       0.06482295, 0.04691762, 0.12228998, 0.0579396 , 0.0986282 ,\n",
            "       0.04682863, 0.18872884, 0.0637376 , 0.17143292, 0.17728179,\n",
            "       0.10867876, 0.22670674, 0.10237628, 0.06233365, 0.20415271,\n",
            "       0.1183183 , 0.13471816, 0.05216757, 0.06655449, 0.1713834 ,\n",
            "       0.07274779, 0.08313703, 0.13598381, 0.07042525, 0.05905767,\n",
            "       0.14290069, 0.11442528, 0.10125687, 0.08562214]), 3: array([0.13781628, 0.10606699, 0.09952901, 0.08678932, 0.09840753,\n",
            "       0.09717839, 0.15530414, 0.11610417, 0.04972309, 0.09636052,\n",
            "       0.09590003, 0.19937423, 0.09250805, 0.19991372, 0.1151357 ,\n",
            "       0.15279621, 0.11309836, 0.08468289, 0.06433315, 0.1396823 ,\n",
            "       0.14915374, 0.12096542, 0.11267195, 0.07699537, 0.08301379,\n",
            "       0.147841  , 0.12353611, 0.17947379, 0.15701896, 0.0946412 ,\n",
            "       0.20268526, 0.13518538, 0.09366258, 0.03721895, 0.20414191,\n",
            "       0.08409028, 0.05670177, 0.12926805, 0.07503   , 0.09320334,\n",
            "       0.04904286, 0.15991373, 0.08280655, 0.13649868, 0.18216036,\n",
            "       0.13155547, 0.18612843, 0.08294634, 0.08295596, 0.21259428,\n",
            "       0.14847013, 0.14945545, 0.0640844 , 0.08106896, 0.14592071,\n",
            "       0.09932708, 0.13684949, 0.11127421, 0.08854388, 0.07310241,\n",
            "       0.11445795, 0.15696401, 0.11709789, 0.09376653]), 7: array([0.05023949, 0.03419987, 0.12442881, 0.05840653, 0.10818843,\n",
            "       0.01630244, 0.25728563, 0.01573   , 0.00860237, 0.17910544,\n",
            "       0.04881922, 0.07693389, 0.02924363, 0.37606751, 0.04028455,\n",
            "       0.05353524, 0.09389309, 0.02117549, 0.0218323 , 0.15968001,\n",
            "       0.16196064, 0.03001266, 0.04927124, 0.03526409, 0.04171073,\n",
            "       0.04065762, 0.05948471, 0.20562807, 0.04319872, 0.04002913,\n",
            "       0.33743645, 0.0859173 , 0.08004192, 0.00557826, 0.3391862 ,\n",
            "       0.0149733 , 0.01385645, 0.05897964, 0.01336121, 0.07129734,\n",
            "       0.02924857, 0.21791755, 0.02372117, 0.21360299, 0.09984355,\n",
            "       0.11204379, 0.30103434, 0.12154815, 0.02101734, 0.12431641,\n",
            "       0.0267015 , 0.0723602 , 0.0167318 , 0.01480794, 0.22115984,\n",
            "       0.01951508, 0.02938783, 0.10162091, 0.03315429, 0.02372785,\n",
            "       0.17743947, 0.03410064, 0.02835786, 0.02773892]), 5: array([0.11726705, 0.18755229, 0.18638842, 0.0303511 , 0.03100559,\n",
            "       0.2022525 , 0.18957512, 0.1441359 , 0.09792718, 0.07282085,\n",
            "       0.02598089, 0.07619211, 0.15280255, 0.14134678, 0.05167218,\n",
            "       0.1327255 , 0.04840603, 0.11817806, 0.06176575, 0.10740092,\n",
            "       0.07864773, 0.12150679, 0.13010246, 0.07154852, 0.05871599,\n",
            "       0.1419627 , 0.07849611, 0.08135735, 0.13801387, 0.07558669,\n",
            "       0.05096913, 0.04733445, 0.02183325, 0.03578872, 0.03262279,\n",
            "       0.12287921, 0.12266299, 0.20143601, 0.10207446, 0.07409028,\n",
            "       0.09019391, 0.04528398, 0.05775919, 0.08022931, 0.16314806,\n",
            "       0.10304727, 0.05138952, 0.11128049, 0.21471605, 0.15607867,\n",
            "       0.16692078, 0.20916095, 0.16108104, 0.13383452, 0.20547128,\n",
            "       0.08222299, 0.04170028, 0.07240833, 0.03870296, 0.06906039,\n",
            "       0.10122058, 0.12698627, 0.37939838, 0.1051702 ]), 8: array([0.11593466, 0.10186033, 0.16149091, 0.10963202, 0.07766145,\n",
            "       0.07429084, 0.13601918, 0.11306022, 0.06999059, 0.14058722,\n",
            "       0.11447763, 0.13558903, 0.12737197, 0.16144686, 0.11402956,\n",
            "       0.11854429, 0.17013647, 0.09521648, 0.13337699, 0.11101506,\n",
            "       0.10515794, 0.11772509, 0.12566152, 0.08801884, 0.11360252,\n",
            "       0.15346807, 0.17442016, 0.18939709, 0.15341654, 0.09481457,\n",
            "       0.14805666, 0.12633891, 0.08157283, 0.06517872, 0.14430755,\n",
            "       0.09218882, 0.08131149, 0.12450248, 0.11885082, 0.09646019,\n",
            "       0.10656106, 0.13964167, 0.10651291, 0.11942925, 0.15509423,\n",
            "       0.09057445, 0.14794798, 0.11456901, 0.13093598, 0.17516609,\n",
            "       0.14184825, 0.12102373, 0.09372968, 0.10245907, 0.08110255,\n",
            "       0.13931958, 0.15402826, 0.09586393, 0.11249112, 0.13501919,\n",
            "       0.12694934, 0.14444545, 0.16628695, 0.1192072 ]), 2: array([0.12526161, 0.11443611, 0.15039311, 0.09356607, 0.08317217,\n",
            "       0.08859479, 0.14696862, 0.12016658, 0.06298356, 0.12799131,\n",
            "       0.0888384 , 0.12459345, 0.12432993, 0.18120118, 0.08958166,\n",
            "       0.11733606, 0.14947819, 0.10562994, 0.10263936, 0.12702841,\n",
            "       0.11738952, 0.11959571, 0.13629402, 0.06410093, 0.10864255,\n",
            "       0.165044  , 0.15479105, 0.16970294, 0.1669162 , 0.09057553,\n",
            "       0.15647122, 0.13003751, 0.08474161, 0.04676836, 0.14224928,\n",
            "       0.09764499, 0.08232632, 0.14319778, 0.12037173, 0.10143942,\n",
            "       0.08847374, 0.14442383, 0.1021217 , 0.12459873, 0.18056211,\n",
            "       0.08325914, 0.14909976, 0.11527086, 0.12493023, 0.19053712,\n",
            "       0.15150176, 0.14184821, 0.09008636, 0.10678702, 0.09552373,\n",
            "       0.12865109, 0.11863239, 0.10883348, 0.09841367, 0.12366397,\n",
            "       0.13302357, 0.13494914, 0.1741777 , 0.12950221]), 0: array([0.09218672, 0.09153191, 0.2604479 , 0.1061918 , 0.04680765,\n",
            "       0.05486973, 0.15916818, 0.08551205, 0.08799052, 0.19600943,\n",
            "       0.09047261, 0.05319216, 0.16043566, 0.13889081, 0.08135959,\n",
            "       0.10306617, 0.20949729, 0.08739343, 0.1783856 , 0.09668482,\n",
            "       0.05873017, 0.14951651, 0.10576827, 0.07071922, 0.10383934,\n",
            "       0.16285453, 0.20390852, 0.18073495, 0.15161361, 0.07930991,\n",
            "       0.11187391, 0.09937937, 0.05025693, 0.08125488, 0.08959228,\n",
            "       0.06817491, 0.09002481, 0.10641179, 0.1267611 , 0.07378706,\n",
            "       0.19121772, 0.10296389, 0.09534736, 0.10295642, 0.1128604 ,\n",
            "       0.04642194, 0.10819896, 0.15195943, 0.17030894, 0.15224551,\n",
            "       0.11716902, 0.11585153, 0.09799701, 0.11506182, 0.05689884,\n",
            "       0.12301023, 0.0843181 , 0.10207433, 0.09538218, 0.18143874,\n",
            "       0.13924175, 0.10067818, 0.21579066, 0.11548632]), 1: array([0.08785102, 0.08709307, 0.22369722, 0.11750636, 0.06403991,\n",
            "       0.04775362, 0.15759068, 0.08101899, 0.07254163, 0.18812185,\n",
            "       0.10270039, 0.07140358, 0.13442617, 0.15900815, 0.09142791,\n",
            "       0.09330967, 0.21607828, 0.08800635, 0.1622414 , 0.11096152,\n",
            "       0.07950162, 0.12968392, 0.11715004, 0.0712447 , 0.11896369,\n",
            "       0.14903233, 0.20456754, 0.19350082, 0.1519084 , 0.07742746,\n",
            "       0.14317092, 0.12014983, 0.06978162, 0.07272503, 0.13027953,\n",
            "       0.0679674 , 0.08297978, 0.10449544, 0.12416439, 0.08811866,\n",
            "       0.1634947 , 0.134699  , 0.10330083, 0.11561041, 0.12382646,\n",
            "       0.0539063 , 0.14250438, 0.14470048, 0.14244654, 0.1580019 ,\n",
            "       0.11929562, 0.10268056, 0.09169696, 0.10003667, 0.06129665,\n",
            "       0.13251223, 0.1033246 , 0.10649753, 0.10719924, 0.17543331,\n",
            "       0.14115263, 0.10746643, 0.1755924 , 0.11914777]), 6: array([0.1189019 , 0.09060732, 0.10759823, 0.10741123, 0.09983272,\n",
            "       0.0669814 , 0.13970453, 0.09641685, 0.04791318, 0.11460173,\n",
            "       0.1228805 , 0.19031063, 0.08888945, 0.18917529, 0.13189442,\n",
            "       0.1303978 , 0.14776785, 0.08466941, 0.09072529, 0.13205802,\n",
            "       0.14202512, 0.10304028, 0.11312896, 0.09184902, 0.1021631 ,\n",
            "       0.13973667, 0.14569992, 0.19879477, 0.14453598, 0.08985448,\n",
            "       0.20170619, 0.14876019, 0.09958177, 0.04544533, 0.2142742 ,\n",
            "       0.07878458, 0.05791086, 0.11127169, 0.08437684, 0.09549391,\n",
            "       0.06179232, 0.17216453, 0.09439202, 0.13715939, 0.16830992,\n",
            "       0.11877957, 0.19538521, 0.08985427, 0.08241156, 0.19612838,\n",
            "       0.13390542, 0.11751563, 0.06172326, 0.07835838, 0.10490902,\n",
            "       0.11669079, 0.16905949, 0.10481976, 0.10978294, 0.09684131,\n",
            "       0.11639624, 0.15860398, 0.10165056, 0.09848056]), 9: array([0.0833029 , 0.2016716 , 0.19410485, 0.01299113, 0.01693181,\n",
            "       0.21841496, 0.24898809, 0.11320683, 0.10196758, 0.05205431,\n",
            "       0.0111944 , 0.06898958, 0.12052266, 0.14497694, 0.03756836,\n",
            "       0.10198067, 0.02947437, 0.11225155, 0.04466856, 0.10531308,\n",
            "       0.08075935, 0.07513083, 0.12801112, 0.07652609, 0.03979425,\n",
            "       0.09802156, 0.05292415, 0.0699843 , 0.09843712, 0.05069944,\n",
            "       0.0385793 , 0.02327597, 0.00855896, 0.02633337, 0.01179064,\n",
            "       0.1203493 , 0.12432715, 0.21082539, 0.06399556, 0.0655534 ,\n",
            "       0.08298394, 0.02555956, 0.03762431, 0.08944481, 0.13562811,\n",
            "       0.11389569, 0.03716494, 0.10885066, 0.22187478, 0.14182296,\n",
            "       0.15044818, 0.18136748, 0.17990081, 0.13540515, 0.25480897,\n",
            "       0.04867151, 0.02344846, 0.07598444, 0.02148904, 0.03889058,\n",
            "       0.08342418, 0.11896746, 0.4580463 , 0.07017718])}\n",
            "sorted [(0, array([0.09218672, 0.09153191, 0.2604479 , 0.1061918 , 0.04680765,\n",
            "       0.05486973, 0.15916818, 0.08551205, 0.08799052, 0.19600943,\n",
            "       0.09047261, 0.05319216, 0.16043566, 0.13889081, 0.08135959,\n",
            "       0.10306617, 0.20949729, 0.08739343, 0.1783856 , 0.09668482,\n",
            "       0.05873017, 0.14951651, 0.10576827, 0.07071922, 0.10383934,\n",
            "       0.16285453, 0.20390852, 0.18073495, 0.15161361, 0.07930991,\n",
            "       0.11187391, 0.09937937, 0.05025693, 0.08125488, 0.08959228,\n",
            "       0.06817491, 0.09002481, 0.10641179, 0.1267611 , 0.07378706,\n",
            "       0.19121772, 0.10296389, 0.09534736, 0.10295642, 0.1128604 ,\n",
            "       0.04642194, 0.10819896, 0.15195943, 0.17030894, 0.15224551,\n",
            "       0.11716902, 0.11585153, 0.09799701, 0.11506182, 0.05689884,\n",
            "       0.12301023, 0.0843181 , 0.10207433, 0.09538218, 0.18143874,\n",
            "       0.13924175, 0.10067818, 0.21579066, 0.11548632])), (1, array([0.08785102, 0.08709307, 0.22369722, 0.11750636, 0.06403991,\n",
            "       0.04775362, 0.15759068, 0.08101899, 0.07254163, 0.18812185,\n",
            "       0.10270039, 0.07140358, 0.13442617, 0.15900815, 0.09142791,\n",
            "       0.09330967, 0.21607828, 0.08800635, 0.1622414 , 0.11096152,\n",
            "       0.07950162, 0.12968392, 0.11715004, 0.0712447 , 0.11896369,\n",
            "       0.14903233, 0.20456754, 0.19350082, 0.1519084 , 0.07742746,\n",
            "       0.14317092, 0.12014983, 0.06978162, 0.07272503, 0.13027953,\n",
            "       0.0679674 , 0.08297978, 0.10449544, 0.12416439, 0.08811866,\n",
            "       0.1634947 , 0.134699  , 0.10330083, 0.11561041, 0.12382646,\n",
            "       0.0539063 , 0.14250438, 0.14470048, 0.14244654, 0.1580019 ,\n",
            "       0.11929562, 0.10268056, 0.09169696, 0.10003667, 0.06129665,\n",
            "       0.13251223, 0.1033246 , 0.10649753, 0.10719924, 0.17543331,\n",
            "       0.14115263, 0.10746643, 0.1755924 , 0.11914777])), (2, array([0.12526161, 0.11443611, 0.15039311, 0.09356607, 0.08317217,\n",
            "       0.08859479, 0.14696862, 0.12016658, 0.06298356, 0.12799131,\n",
            "       0.0888384 , 0.12459345, 0.12432993, 0.18120118, 0.08958166,\n",
            "       0.11733606, 0.14947819, 0.10562994, 0.10263936, 0.12702841,\n",
            "       0.11738952, 0.11959571, 0.13629402, 0.06410093, 0.10864255,\n",
            "       0.165044  , 0.15479105, 0.16970294, 0.1669162 , 0.09057553,\n",
            "       0.15647122, 0.13003751, 0.08474161, 0.04676836, 0.14224928,\n",
            "       0.09764499, 0.08232632, 0.14319778, 0.12037173, 0.10143942,\n",
            "       0.08847374, 0.14442383, 0.1021217 , 0.12459873, 0.18056211,\n",
            "       0.08325914, 0.14909976, 0.11527086, 0.12493023, 0.19053712,\n",
            "       0.15150176, 0.14184821, 0.09008636, 0.10678702, 0.09552373,\n",
            "       0.12865109, 0.11863239, 0.10883348, 0.09841367, 0.12366397,\n",
            "       0.13302357, 0.13494914, 0.1741777 , 0.12950221])), (3, array([0.13781628, 0.10606699, 0.09952901, 0.08678932, 0.09840753,\n",
            "       0.09717839, 0.15530414, 0.11610417, 0.04972309, 0.09636052,\n",
            "       0.09590003, 0.19937423, 0.09250805, 0.19991372, 0.1151357 ,\n",
            "       0.15279621, 0.11309836, 0.08468289, 0.06433315, 0.1396823 ,\n",
            "       0.14915374, 0.12096542, 0.11267195, 0.07699537, 0.08301379,\n",
            "       0.147841  , 0.12353611, 0.17947379, 0.15701896, 0.0946412 ,\n",
            "       0.20268526, 0.13518538, 0.09366258, 0.03721895, 0.20414191,\n",
            "       0.08409028, 0.05670177, 0.12926805, 0.07503   , 0.09320334,\n",
            "       0.04904286, 0.15991373, 0.08280655, 0.13649868, 0.18216036,\n",
            "       0.13155547, 0.18612843, 0.08294634, 0.08295596, 0.21259428,\n",
            "       0.14847013, 0.14945545, 0.0640844 , 0.08106896, 0.14592071,\n",
            "       0.09932708, 0.13684949, 0.11127421, 0.08854388, 0.07310241,\n",
            "       0.11445795, 0.15696401, 0.11709789, 0.09376653])), (4, array([0.11478377, 0.09573872, 0.11334106, 0.07356598, 0.10375725,\n",
            "       0.07664447, 0.21082932, 0.08269825, 0.03474149, 0.12407912,\n",
            "       0.07467396, 0.14944355, 0.07321193, 0.26733924, 0.07716078,\n",
            "       0.10625511, 0.1193089 , 0.07339835, 0.04522939, 0.15713954,\n",
            "       0.16908594, 0.09109797, 0.1118566 , 0.04654253, 0.07798271,\n",
            "       0.12124483, 0.10925392, 0.18708963, 0.13651516, 0.07134686,\n",
            "       0.25613617, 0.12832826, 0.09289955, 0.01988344, 0.23898355,\n",
            "       0.06482295, 0.04691762, 0.12228998, 0.0579396 , 0.0986282 ,\n",
            "       0.04682863, 0.18872884, 0.0637376 , 0.17143292, 0.17728179,\n",
            "       0.10867876, 0.22670674, 0.10237628, 0.06233365, 0.20415271,\n",
            "       0.1183183 , 0.13471816, 0.05216757, 0.06655449, 0.1713834 ,\n",
            "       0.07274779, 0.08313703, 0.13598381, 0.07042525, 0.05905767,\n",
            "       0.14290069, 0.11442528, 0.10125687, 0.08562214])), (5, array([0.11726705, 0.18755229, 0.18638842, 0.0303511 , 0.03100559,\n",
            "       0.2022525 , 0.18957512, 0.1441359 , 0.09792718, 0.07282085,\n",
            "       0.02598089, 0.07619211, 0.15280255, 0.14134678, 0.05167218,\n",
            "       0.1327255 , 0.04840603, 0.11817806, 0.06176575, 0.10740092,\n",
            "       0.07864773, 0.12150679, 0.13010246, 0.07154852, 0.05871599,\n",
            "       0.1419627 , 0.07849611, 0.08135735, 0.13801387, 0.07558669,\n",
            "       0.05096913, 0.04733445, 0.02183325, 0.03578872, 0.03262279,\n",
            "       0.12287921, 0.12266299, 0.20143601, 0.10207446, 0.07409028,\n",
            "       0.09019391, 0.04528398, 0.05775919, 0.08022931, 0.16314806,\n",
            "       0.10304727, 0.05138952, 0.11128049, 0.21471605, 0.15607867,\n",
            "       0.16692078, 0.20916095, 0.16108104, 0.13383452, 0.20547128,\n",
            "       0.08222299, 0.04170028, 0.07240833, 0.03870296, 0.06906039,\n",
            "       0.10122058, 0.12698627, 0.37939838, 0.1051702 ])), (6, array([0.1189019 , 0.09060732, 0.10759823, 0.10741123, 0.09983272,\n",
            "       0.0669814 , 0.13970453, 0.09641685, 0.04791318, 0.11460173,\n",
            "       0.1228805 , 0.19031063, 0.08888945, 0.18917529, 0.13189442,\n",
            "       0.1303978 , 0.14776785, 0.08466941, 0.09072529, 0.13205802,\n",
            "       0.14202512, 0.10304028, 0.11312896, 0.09184902, 0.1021631 ,\n",
            "       0.13973667, 0.14569992, 0.19879477, 0.14453598, 0.08985448,\n",
            "       0.20170619, 0.14876019, 0.09958177, 0.04544533, 0.2142742 ,\n",
            "       0.07878458, 0.05791086, 0.11127169, 0.08437684, 0.09549391,\n",
            "       0.06179232, 0.17216453, 0.09439202, 0.13715939, 0.16830992,\n",
            "       0.11877957, 0.19538521, 0.08985427, 0.08241156, 0.19612838,\n",
            "       0.13390542, 0.11751563, 0.06172326, 0.07835838, 0.10490902,\n",
            "       0.11669079, 0.16905949, 0.10481976, 0.10978294, 0.09684131,\n",
            "       0.11639624, 0.15860398, 0.10165056, 0.09848056])), (7, array([0.05023949, 0.03419987, 0.12442881, 0.05840653, 0.10818843,\n",
            "       0.01630244, 0.25728563, 0.01573   , 0.00860237, 0.17910544,\n",
            "       0.04881922, 0.07693389, 0.02924363, 0.37606751, 0.04028455,\n",
            "       0.05353524, 0.09389309, 0.02117549, 0.0218323 , 0.15968001,\n",
            "       0.16196064, 0.03001266, 0.04927124, 0.03526409, 0.04171073,\n",
            "       0.04065762, 0.05948471, 0.20562807, 0.04319872, 0.04002913,\n",
            "       0.33743645, 0.0859173 , 0.08004192, 0.00557826, 0.3391862 ,\n",
            "       0.0149733 , 0.01385645, 0.05897964, 0.01336121, 0.07129734,\n",
            "       0.02924857, 0.21791755, 0.02372117, 0.21360299, 0.09984355,\n",
            "       0.11204379, 0.30103434, 0.12154815, 0.02101734, 0.12431641,\n",
            "       0.0267015 , 0.0723602 , 0.0167318 , 0.01480794, 0.22115984,\n",
            "       0.01951508, 0.02938783, 0.10162091, 0.03315429, 0.02372785,\n",
            "       0.17743947, 0.03410064, 0.02835786, 0.02773892])), (8, array([0.11593466, 0.10186033, 0.16149091, 0.10963202, 0.07766145,\n",
            "       0.07429084, 0.13601918, 0.11306022, 0.06999059, 0.14058722,\n",
            "       0.11447763, 0.13558903, 0.12737197, 0.16144686, 0.11402956,\n",
            "       0.11854429, 0.17013647, 0.09521648, 0.13337699, 0.11101506,\n",
            "       0.10515794, 0.11772509, 0.12566152, 0.08801884, 0.11360252,\n",
            "       0.15346807, 0.17442016, 0.18939709, 0.15341654, 0.09481457,\n",
            "       0.14805666, 0.12633891, 0.08157283, 0.06517872, 0.14430755,\n",
            "       0.09218882, 0.08131149, 0.12450248, 0.11885082, 0.09646019,\n",
            "       0.10656106, 0.13964167, 0.10651291, 0.11942925, 0.15509423,\n",
            "       0.09057445, 0.14794798, 0.11456901, 0.13093598, 0.17516609,\n",
            "       0.14184825, 0.12102373, 0.09372968, 0.10245907, 0.08110255,\n",
            "       0.13931958, 0.15402826, 0.09586393, 0.11249112, 0.13501919,\n",
            "       0.12694934, 0.14444545, 0.16628695, 0.1192072 ])), (9, array([0.0833029 , 0.2016716 , 0.19410485, 0.01299113, 0.01693181,\n",
            "       0.21841496, 0.24898809, 0.11320683, 0.10196758, 0.05205431,\n",
            "       0.0111944 , 0.06898958, 0.12052266, 0.14497694, 0.03756836,\n",
            "       0.10198067, 0.02947437, 0.11225155, 0.04466856, 0.10531308,\n",
            "       0.08075935, 0.07513083, 0.12801112, 0.07652609, 0.03979425,\n",
            "       0.09802156, 0.05292415, 0.0699843 , 0.09843712, 0.05069944,\n",
            "       0.0385793 , 0.02327597, 0.00855896, 0.02633337, 0.01179064,\n",
            "       0.1203493 , 0.12432715, 0.21082539, 0.06399556, 0.0655534 ,\n",
            "       0.08298394, 0.02555956, 0.03762431, 0.08944481, 0.13562811,\n",
            "       0.11389569, 0.03716494, 0.10885066, 0.22187478, 0.14182296,\n",
            "       0.15044818, 0.18136748, 0.17990081, 0.13540515, 0.25480897,\n",
            "       0.04867151, 0.02344846, 0.07598444, 0.02148904, 0.03889058,\n",
            "       0.08342418, 0.11896746, 0.4580463 , 0.07017718]))]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00e27416b0e5401f9ae04d528cdf3242",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([33, 30, 76, 33, 96,  3, 27, 96, 11, 27, 96,  5, 78,  3, 76, 78, 33, 62,\n",
            "         5, 62,  3,  5, 11, 96, 30, 33, 76,  5,  5, 11, 96,  5, 27, 30, 62, 76,\n",
            "        11,  3, 62, 30, 78, 62, 30, 33, 30,  5,  5, 96, 27, 78, 62, 33, 78, 33,\n",
            "        62, 27,  5,  3,  3, 76, 27,  3, 96, 78, 78, 62, 30, 96, 30,  5, 96, 96,\n",
            "        30,  3, 27,  3, 27, 33, 62,  3, 62, 76, 78, 76, 11, 76, 33,  5,  5, 30,\n",
            "        78,  3, 27, 62, 33, 27, 78,  3,  5, 33, 96,  3, 11,  3, 62,  5,  5, 78,\n",
            "        30, 96, 30, 30, 11, 30, 62, 11, 62, 33, 76, 76, 27, 33, 33,  3,  5, 76,\n",
            "        30,  3])\n",
            "tensor([1, 9, 5, 1, 0, 2, 8, 0, 4, 8, 0, 3, 6, 2, 5, 6, 1, 7, 3, 7, 2, 3, 4, 0,\n",
            "        9, 1, 5, 3, 3, 4, 0, 3, 8, 9, 7, 5, 4, 2, 7, 9, 6, 7, 9, 1, 9, 3, 3, 0,\n",
            "        8, 6, 7, 1, 6, 1, 7, 8, 3, 2, 2, 5, 8, 2, 0, 6, 6, 7, 9, 0, 9, 3, 0, 0,\n",
            "        9, 2, 8, 2, 8, 1, 7, 2, 7, 5, 6, 5, 4, 5, 1, 3, 3, 9, 6, 2, 8, 7, 1, 8,\n",
            "        6, 2, 3, 1, 0, 2, 4, 2, 7, 3, 3, 6, 9, 0, 9, 9, 4, 9, 7, 4, 7, 1, 5, 5,\n",
            "        8, 1, 1, 2, 3, 5, 9, 2])\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6a755b310f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnemonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m203\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-af317131aa44>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexemplar_level_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_training_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# compute means of exemplar set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-af317131aa44>\u001b[0m in \u001b[0;36mexemplar_level_optimization\u001b[0;34m(self, m, task_num, current_task_indices)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---start mnemonics updating---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_exemplar_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-af317131aa44>\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self, m, finetuning_idxs, training_idxs, mnemonics_to_optimize, batch_size, new, lr, momentum, weight_decay, milestones, gamma, tuning_epochs, updating_epochs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mlabels_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# al secondo batch di classi per i new mnemonics le uscite sono sempre 10 ma le label vanno da 10 a 19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:235"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUjLtvTmwE82"
      },
      "source": [
        "xzz = {0:1, 1:2}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7F2l6oS_z9u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}